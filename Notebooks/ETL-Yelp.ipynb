{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL-Yelp!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Se configura pandas para que se muestre la totalidad de las columnas del dataframe.\n",
    "pd.options.display.max_columns = None\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutas a los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_buisness = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\business.pkl'\n",
    "path_checkin = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\checkin.json'\n",
    "path_review = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.json'\n",
    "path_review_parquet = \"C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.parquet\"\n",
    "path_tip = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\tip.json'\n",
    "path_user = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\user.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"business.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_pickle(path_buisness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "\n",
       "                           address           city state postal_code  \\\n",
       "0           1616 Chapala St, Ste 2  Santa Barbara   NaN       93101   \n",
       "1  87 Grasso Plaza Shopping Center         Affton   NaN       63123   \n",
       "2             5255 E Broadway Blvd         Tucson   NaN       85711   \n",
       "\n",
       "    latitude   longitude stars review_count is_open  \\\n",
       "0  34.426679 -119.711197   5.0            7       0   \n",
       "1  38.551126  -90.335695   3.0           15       1   \n",
       "2  32.223236 -110.880452   3.5           22       0   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                      {'ByAppointmentOnly': 'True'}   \n",
       "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
       "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2  Department Stores, Shopping, Fashion, Home & G...   \n",
       "\n",
       "                                               hours business_id name address  \\\n",
       "0                                               None         NaN  NaN     NaN   \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...         NaN  NaN     NaN   \n",
       "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...         NaN  NaN     NaN   \n",
       "\n",
       "  city state postal_code latitude longitude stars review_count is_open  \\\n",
       "0  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "1  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "2  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "\n",
       "  attributes categories hours  \n",
       "0        NaN        NaN   NaN  \n",
       "1        NaN        NaN   NaN  \n",
       "2        NaN        NaN   NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150346 entries, 0 to 150345\n",
      "Data columns (total 28 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   business_id   150346 non-null  object\n",
      " 1   name          150346 non-null  object\n",
      " 2   address       150346 non-null  object\n",
      " 3   city          150346 non-null  object\n",
      " 4   state         150343 non-null  object\n",
      " 5   postal_code   150346 non-null  object\n",
      " 6   latitude      150346 non-null  object\n",
      " 7   longitude     150346 non-null  object\n",
      " 8   stars         150346 non-null  object\n",
      " 9   review_count  150346 non-null  object\n",
      " 10  is_open       150346 non-null  object\n",
      " 11  attributes    136602 non-null  object\n",
      " 12  categories    150243 non-null  object\n",
      " 13  hours         127123 non-null  object\n",
      " 14  business_id   5 non-null       object\n",
      " 15  name          5 non-null       object\n",
      " 16  address       5 non-null       object\n",
      " 17  city          5 non-null       object\n",
      " 18  state         5 non-null       object\n",
      " 19  postal_code   5 non-null       object\n",
      " 20  latitude      5 non-null       object\n",
      " 21  longitude     5 non-null       object\n",
      " 22  stars         5 non-null       object\n",
      " 23  review_count  5 non-null       object\n",
      " 24  is_open       5 non-null       object\n",
      " 25  attributes    5 non-null       object\n",
      " 26  categories    5 non-null       object\n",
      " 27  hours         5 non-null       object\n",
      "dtypes: object(28)\n",
      "memory usage: 33.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id          0\n",
       "name                 0\n",
       "address              0\n",
       "city                 0\n",
       "state                3\n",
       "postal_code          0\n",
       "latitude             0\n",
       "longitude            0\n",
       "stars                0\n",
       "review_count         0\n",
       "is_open              0\n",
       "attributes       13744\n",
       "categories         103\n",
       "hours            23223\n",
       "business_id     150341\n",
       "name            150341\n",
       "address         150341\n",
       "city            150341\n",
       "state           150341\n",
       "postal_code     150341\n",
       "latitude        150341\n",
       "longitude       150341\n",
       "stars           150341\n",
       "review_count    150341\n",
       "is_open         150341\n",
       "attributes      150341\n",
       "categories      150341\n",
       "hours           150341\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar la existencia de columnas duplicadas cuyo contenido está compuesto en su mayor parte de valores nulos se procede a eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business.loc[:, ~df_business.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corrobora que se hayan efectuado los cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id         0\n",
       "name                0\n",
       "address             0\n",
       "city                0\n",
       "state               3\n",
       "postal_code         0\n",
       "latitude            0\n",
       "longitude           0\n",
       "stars               0\n",
       "review_count        0\n",
       "is_open             0\n",
       "attributes      13744\n",
       "categories        103\n",
       "hours           23223\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"business_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados_business = df_business['business_id'].duplicated()\n",
    "df_duplicados_business = df_business[duplicados_business]\n",
    "df_duplicados_business.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna \"business_id\" no presenta valores duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas \"categories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de categorías únicas es 1311\n"
     ]
    }
   ],
   "source": [
    "categories_lists = df_business['categories'].str.split(', ')\n",
    "\n",
    "# Apilar todas las listas resultantes en una sola lista\n",
    "all_categories = [category for sublist in categories_lists if sublist is not None for category in sublist]\n",
    "\n",
    "# Obtener los valores únicos de la lista\n",
    "unique_categories = set(all_categories)\n",
    "print(f'La cantidad de categorías únicas es {len(unique_categories)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el dataframe \"df_restaurants\" en base a las filas que contienen el valor \"restaurant\" y \"mex\" dentro de ellas con el objetivo de reducir la cantidad de filas a solo las que serán utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_mex_restaurant = df_business['categories'].str.contains('(?=.*mex)(?=.*restaurant)', case=False, na=False)\n",
    "df_restaurants = df_business[filtro_mex_restaurant]\n",
    "df_restaurants = df_restaurants.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4768 entries, 0 to 4767\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   business_id   4768 non-null   object\n",
      " 1   name          4768 non-null   object\n",
      " 2   address       4768 non-null   object\n",
      " 3   city          4768 non-null   object\n",
      " 4   state         4768 non-null   object\n",
      " 5   postal_code   4768 non-null   object\n",
      " 6   latitude      4768 non-null   object\n",
      " 7   longitude     4768 non-null   object\n",
      " 8   stars         4768 non-null   object\n",
      " 9   review_count  4768 non-null   object\n",
      " 10  is_open       4768 non-null   object\n",
      " 11  attributes    4689 non-null   object\n",
      " 12  categories    4768 non-null   object\n",
      " 13  hours         4073 non-null   object\n",
      "dtypes: object(14)\n",
      "memory usage: 521.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_restaurants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"state\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de valores nulos presente en la columna \"state\" es 0.\n"
     ]
    }
   ],
   "source": [
    "nulos_estado = df_restaurants['state'].isnull().sum()\n",
    "print(f'La cantidad de valores nulos presente en la columna \"state\" es {nulos_estado}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"myGeocoder\")\n",
    "\n",
    "# Función para obtener el estado a partir de las coordenadas\n",
    "def get_state(lat, lon):\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), language='en')\n",
    "        address = location.raw['address']\n",
    "        return address.get('state', '')\n",
    "    except (GeocoderTimedOut, GeocoderServiceError):\n",
    "        return None\n",
    "\n",
    "# Aplicar la función a cada fila del DataFrame\n",
    "df_restaurants['state'] = df_restaurants.apply(lambda row: get_state(row['latitude'], row['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "Pennsylvania    718\n",
      "Florida         700\n",
      "Arizona         540\n",
      "Tennessee       520\n",
      "Indiana         511\n",
      "Missouri        360\n",
      "Nevada          271\n",
      "Louisiana       241\n",
      "California      191\n",
      "New Jersey      182\n",
      "Idaho           153\n",
      "Illinois        104\n",
      "Delaware         86\n",
      "Alberta          61\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top = df_restaurants['state'].value_counts().head(14)\n",
    "\n",
    "print(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Taco Bell                        363\n",
       "Chipotle Mexican Grill           156\n",
       "Jack in the Box                   96\n",
       "QDOBA Mexican Eats                81\n",
       "Chili's                           80\n",
       "Moe's Southwest Grill             50\n",
       "Tijuana Flats                     25\n",
       "Taco Bus                          14\n",
       "Del Taco                          14\n",
       "Los Betos                         13\n",
       "Las Palmas Mexican Restaurant     12\n",
       "California Tortilla               10\n",
       "Baja Fresh                        10\n",
       "Mucho Burrito                      9\n",
       "Blue Coast Burrito                 9\n",
       "La Hacienda                        9\n",
       "Pancheros Mexican Grill            9\n",
       "El Pollo Loco                      9\n",
       "Taco Del Mar                       9\n",
       "El Rodeo                           8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_r = df_restaurants['name'].value_counts().head(20)\n",
    "top_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siendo Florida el estado objetivo por su gran poblacion de origen latino y concentración de restaurantes se opta por filtrar las filas que correspondan a ese estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_florida = df_restaurants['state'].str.contains('FL', case=False, na=False)\n",
    "df_florida = df_restaurants[filtro_florida]\n",
    "df_business = df_florida.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   business_id   700 non-null    object\n",
      " 1   name          700 non-null    object\n",
      " 2   address       700 non-null    object\n",
      " 3   city          700 non-null    object\n",
      " 4   state         700 non-null    object\n",
      " 5   postal_code   700 non-null    object\n",
      " 6   latitude      700 non-null    object\n",
      " 7   longitude     700 non-null    object\n",
      " 8   stars         700 non-null    object\n",
      " 9   review_count  700 non-null    object\n",
      " 10  is_open       700 non-null    object\n",
      " 11  attributes    689 non-null    object\n",
      " 12  categories    700 non-null    object\n",
      " 13  hours         630 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"is_open\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se opta por eliminar la columnas debido a que no aporta datos relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_final = df_business.drop(['is_open'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Al haberse realizado una reducción de los datos a través del dataframe \"df_florida\" se usará los datos de la columna \"business_id\" para descartar las filas de los demás datasets que no coincidan con dicho ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El filtro consta de 700 ID's únicos\n"
     ]
    }
   ],
   "source": [
    "business_ids = df_business_final['business_id'].unique()\n",
    "print(f\"El filtro consta de {len(business_ids)} ID's únicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"review.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extraen los datos del archivo \"review.json\" para pasarlo a formato parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = \"C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.json\"\n",
    "path_review_parquet = \"C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.parquet\"\n",
    "\n",
    "# Se lee el archivo json en fragmentos para manejar archivos grandes\n",
    "chunksize = 100000  # Número de líneas por fragmento\n",
    "chunks = pd.read_json(path_review, lines=True, chunksize=chunksize)\n",
    "\n",
    "# Se crea una lista para almacenar las tablas PyArrow\n",
    "tables = []\n",
    "\n",
    "# Se procesa cada fragmento y convertirlo en una tabla PyArrow\n",
    "for chunk in chunks:\n",
    "    table = pa.Table.from_pandas(chunk)\n",
    "    tables.append(table)\n",
    "\n",
    "# Concatenar todas las tablas en una sola tabla\n",
    "final_table = pa.concat_tables(tables)\n",
    "\n",
    "# Guardar la tabla final en un archivo Parquet\n",
    "pq.write_table(final_table, path_review_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se abre el archivo\n",
    "parquet_file = pq.ParquetFile(path_review_parquet)\n",
    "\n",
    "# Se obtiene el número total de grupos de filas.\n",
    "total_row_groups = parquet_file.num_row_groups\n",
    "\n",
    "# Se genera un bucle para leer los fragmentos del archivo.\n",
    "for i in range(0, total_row_groups):\n",
    "    # Se lee el fragmento del archivo.\n",
    "    lote = parquet_file.read_row_group(i, use_pandas_metadata=True).to_pandas()\n",
    "\n",
    "    # Se guarda el fragmento del archivo en un archivo parquet.\n",
    "    lote.to_parquet(f\"review_{i}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutas a los archivos seccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_0 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_0.parquet'\n",
    "path_1 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_1.parquet'\n",
    "path_2 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_2.parquet'\n",
    "path_3 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_3.parquet'\n",
    "path_4 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_4.parquet'\n",
    "path_5 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_5.parquet'\n",
    "path_6 ='C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review_6.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeo_de_nulos_parquet(file_path):\n",
    "    try:\n",
    "        # Leer el archivo Parquet en un DataFrame\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Verificar valores nulos\n",
    "        null_counts = df.isnull().sum()\n",
    "        total_nulls = null_counts.sum()\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f'Archivo: {os.path.basename(file_path)}')\n",
    "        print(f'Total de valores nulos: {total_nulls}')\n",
    "        print('Valores nulos por columna:')\n",
    "        print(null_counts)\n",
    "        print('-' * 40)\n",
    "    except Exception as e:\n",
    "        print(f'Error al procesar el archivo {file_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_0.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_1.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_2.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_3.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_4.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_5.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_6.parquet\n",
      "Total de valores nulos: 0\n",
      "Valores nulos por columna:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_de_nulos_parquet(path_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concluye que no hay presencia de datos nulos en ninguno de los archivos fraccionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequeo_eliminación_duplicados(ruta):\n",
    "    try:\n",
    "        # Se lee el archivo Parquet en un DataFrame.\n",
    "        df = pd.read_parquet(ruta)\n",
    "        \n",
    "        # Se verifica duplicados.\n",
    "        duplicates = df.duplicated().sum()\n",
    "        \n",
    "        if duplicates > 0:\n",
    "            print(f'Archivo: {os.path.basename(ruta)}')\n",
    "            print(f'Total de filas duplicadas encontradas: {duplicates}')\n",
    "            \n",
    "            # Se eliminan duplicados.\n",
    "            df = df.drop_duplicates()\n",
    "            print(f'Filas duplicadas eliminadas. Total de filas restantes: {len(df)}')\n",
    "            \n",
    "            # Se guarda el DataFrame sin duplicados archivo parquet\n",
    "            df.to_parquet(ruta, index=False)\n",
    "            print(f'Archivo actualizado sin duplicados: {ruta}')\n",
    "        else:\n",
    "            print(f'Archivo: {os.path.basename(ruta)}')\n",
    "            print('No se encontraron filas duplicadas.')\n",
    "        \n",
    "        print('-' * 40)\n",
    "    except Exception as e:\n",
    "        print(f'Error al procesar el archivo {ruta}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_0.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_1.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_2.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_3.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_4.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_5.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: review_6.parquet\n",
      "No se encontraron filas duplicadas.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chequeo_eliminación_duplicados(path_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se observan filas duplicadas en ninguno de los archivos fraccionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplicará un filtro a cada fragmento para que se reduzca el número de filas a las necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_parquet(path_0, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 1048576 filas'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_0)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_0_final = df_0[df_0['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_0_final = df_0_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_parquet(path_1, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 1048576 filas'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_1)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_1_final = df_1[df_1['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_1_final = df_1_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_parquet(path_2, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 1048576 filas'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_2)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_2_final = df_2[df_2['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_2_final = df_2_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_parquet(path_3, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 1048576 filas'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_3)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_3_final = df_3[df_3['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_3_final = df_3_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_parquet(path_4, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 1048576 filas'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_4)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_4_final = df_4[df_4['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_4_final = df_4_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.read_parquet(path_5, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 1048576 filas'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_5)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_5_final = df_5[df_5['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_5_final = df_5_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6 = pd.read_parquet(path_6, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El dataframe presenta 698824 filas'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f'El dataframe presenta {len(df_6)} filas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_6_final = df_6[df_6['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_6_final = df_6_final.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filas totales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de filas original es 6990280\n"
     ]
    }
   ],
   "source": [
    "total_filas_raw = len(df_0) + len(df_1) + len(df_2) + len(df_3) + len(df_4) + len(df_5) + len(df_6)\n",
    "print(f\"El número de filas original es {total_filas_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación de dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.concat([df_0_final, df_1_final, df_2_final, df_3_final, df_4_final, df_5_final, df_6_final], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cCs7yPSyk8NdA-Ufoz_7hw</td>\n",
       "      <td>FodM8aoGMQO2zsQCQxBTYQ</td>\n",
       "      <td>v5ktgWMAARaczTMh2rAJKg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The service here has gone down. We used to go ...</td>\n",
       "      <td>2017-12-27 02:57:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eP-S5CuNNVdGsfmVc5BXpg</td>\n",
       "      <td>jDLeW4d-8WqMkikCTHFJ5g</td>\n",
       "      <td>kJpoduG3wdA35WzOF_T1Aw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Only the best Mexican food in Florida!!!!  Sin...</td>\n",
       "      <td>2016-04-23 18:01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8KDl6ZlqXL4zlM8ptQWUMg</td>\n",
       "      <td>0O5O06pC4YgqnLVm5MznJg</td>\n",
       "      <td>V8H6z5ulGJEkaFUyRfmLKw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The food was great, the service excellent.  Ha...</td>\n",
       "      <td>2015-06-21 01:54:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  cCs7yPSyk8NdA-Ufoz_7hw  FodM8aoGMQO2zsQCQxBTYQ  v5ktgWMAARaczTMh2rAJKg   \n",
       "1  eP-S5CuNNVdGsfmVc5BXpg  jDLeW4d-8WqMkikCTHFJ5g  kJpoduG3wdA35WzOF_T1Aw   \n",
       "2  8KDl6ZlqXL4zlM8ptQWUMg  0O5O06pC4YgqnLVm5MznJg  V8H6z5ulGJEkaFUyRfmLKw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      2       0      0     0   \n",
       "1      5       0      0     0   \n",
       "2      5       0      0     0   \n",
       "\n",
       "                                                text                date  \n",
       "0  The service here has gone down. We used to go ... 2017-12-27 02:57:57  \n",
       "1  Only the best Mexican food in Florida!!!!  Sin... 2016-04-23 18:01:24  \n",
       "2  The food was great, the service excellent.  Ha... 2015-06-21 01:54:07  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fecha mínima es 2006-02-02 19:09:03 y la fecha máxima es 2022-01-19 19:21:56\n"
     ]
    }
   ],
   "source": [
    "fecha_maxima = df_review['date'].max()\n",
    "fecha_minima = df_review['date'].min()\n",
    "\n",
    "print(f'La fecha mínima es {fecha_minima} y la fecha máxima es {fecha_maxima}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener un contexto en el marco más actualizado se procede a utilizar los datos que se encuentran dentro de un rango temporal entre 2017 y 2021. Por lo tanto, se procede a limitar las filas usadas a las que se encuentren en dicho rango temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_review[df_review['date'].between('2017-01-01', '2021-12-31', inclusive='both')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corrobora que se hayan realizado los cambios correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fecha mínima es 2017-01-01 01:30:23 y la fecha máxima es 2021-12-30 23:36:35\n"
     ]
    }
   ],
   "source": [
    "fecha_maxima = df_review['date'].max()\n",
    "fecha_minima = df_review['date'].min()\n",
    "\n",
    "print(f'La fecha mínima es {fecha_minima} y la fecha máxima es {fecha_maxima}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean columnas específicas para cada formato temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review['date'] = pd.to_datetime(df_review['date'])\n",
    "\n",
    "# Se crea una nueva columna con la fecha en formato 'YYYY-MM-DD'.\n",
    "df_review['fecha'] = df_review['date'].dt.date\n",
    "\n",
    "# Se crea una nueva columna con la hora en formato de 24 horas enteras.\n",
    "df_review['hora'] = df_review['date'].dt.hour\n",
    "\n",
    "df_review['dia_semana'] = df_review['date'].dt.strftime('%A')\n",
    "\n",
    "# Se crea un diccionario para mapear los dias de la semana en español.\n",
    "dias_semana_es = {\n",
    "    'Monday': 'Lunes',\n",
    "    'Tuesday': 'Martes',\n",
    "    'Wednesday': 'Miércoles',\n",
    "    'Thursday': 'Jueves',\n",
    "    'Friday': 'Viernes',\n",
    "    'Saturday': 'Sábado',\n",
    "    'Sunday': 'Domingo'\n",
    "}\n",
    "df_review['dia_semana'] = df_review['dia_semana'].map(dias_semana_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>dia_semana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cCs7yPSyk8NdA-Ufoz_7hw</td>\n",
       "      <td>FodM8aoGMQO2zsQCQxBTYQ</td>\n",
       "      <td>v5ktgWMAARaczTMh2rAJKg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The service here has gone down. We used to go ...</td>\n",
       "      <td>2017-12-27 02:57:57</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2</td>\n",
       "      <td>Miércoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8ZDUB-Y6JFxex541jHprGg</td>\n",
       "      <td>bIXslp2Sojhp9OcA-PNTvw</td>\n",
       "      <td>-zsvmEbkd-K9K2DAAKqiEQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thoroughly enjoyed our visit to Salty's this e...</td>\n",
       "      <td>2018-07-17 02:59:05</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2</td>\n",
       "      <td>Martes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naht5FrBGZDFGjwCQ-DyMw</td>\n",
       "      <td>QKoP7XabOXXWIkTwvYyCiA</td>\n",
       "      <td>xGUAa3xa8KsmbolC3XboQg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Xtreme Tacos has become one of my favorite pla...</td>\n",
       "      <td>2017-10-02 16:29:35</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>16</td>\n",
       "      <td>Lunes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  cCs7yPSyk8NdA-Ufoz_7hw  FodM8aoGMQO2zsQCQxBTYQ  v5ktgWMAARaczTMh2rAJKg   \n",
       "7  8ZDUB-Y6JFxex541jHprGg  bIXslp2Sojhp9OcA-PNTvw  -zsvmEbkd-K9K2DAAKqiEQ   \n",
       "8  Naht5FrBGZDFGjwCQ-DyMw  QKoP7XabOXXWIkTwvYyCiA  xGUAa3xa8KsmbolC3XboQg   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      2       0      0     0   \n",
       "7      5       0      0     0   \n",
       "8      5       0      0     0   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  The service here has gone down. We used to go ... 2017-12-27 02:57:57   \n",
       "7  Thoroughly enjoyed our visit to Salty's this e... 2018-07-17 02:59:05   \n",
       "8  Xtreme Tacos has become one of my favorite pla... 2017-10-02 16:29:35   \n",
       "\n",
       "        fecha  hora dia_semana  \n",
       "0  2017-12-27     2  Miércoles  \n",
       "7  2018-07-17     2     Martes  \n",
       "8  2017-10-02    16      Lunes  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_final = df_review.reset_index(drop=True, inplace=False)\n",
    "df_review_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como se ha realizado una reducción de los datos a nivel temporal a través del dataframe \"df_reviews\" se usará los datos de la columna \"business_id\" para descartar las filas de los demás datasets que no coincidan con dicho ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El filtro consta de 625 ID's únicos\n"
     ]
    }
   ],
   "source": [
    "# Se genera el filtro buisness_ids para continuar con la reducción de los dataframes.\n",
    "business_ids = df_review_final['business_id'].unique()\n",
    "print(f\"El filtro consta de {len(business_ids)} ID's únicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### También se genera un segundo filtro para los dataset que en lugar de presentar una columna \"business_id\" solo muestren una columna \"user_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El filtro consta de 31344 ID's únicos\n"
     ]
    }
   ],
   "source": [
    "# Se genera el filtro buisness_ids para continuar con la reducción de los dataframes.\n",
    "user_ids = df_review_final['user_id'].unique()\n",
    "print(f\"El filtro consta de {len(user_ids)} ID's únicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"checkin.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin = []\n",
    "\n",
    "with open(path_checkin, 'r') as archivo:\n",
    "    #Se crea un loop para ir incorporando los elementos a la lista.\n",
    "    for linea in archivo:\n",
    "        data= json.loads(linea)\n",
    "        checkin.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--0iUa4sNDFiZFrAdIWhZQ</td>\n",
       "      <td>2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--30_8IhuyMHbSOcNWd6DQ</td>\n",
       "      <td>2013-06-14 23:29:17, 2014-08-13 23:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--7jw19RH9JKXgFohspgQw</td>\n",
       "      <td>2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               date\n",
       "0  ---kPU91CF4Lq2-WlRu9Lw  2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...\n",
       "1  --0iUa4sNDFiZFrAdIWhZQ  2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...\n",
       "2  --30_8IhuyMHbSOcNWd6DQ           2013-06-14 23:29:17, 2014-08-13 23:20:22\n",
       "3  --7PUidqRWpRSpXebiyxTg  2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...\n",
       "4  --7jw19RH9JKXgFohspgQw  2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkin = pd.DataFrame(checkin)\n",
    "df_checkin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131930 entries, 0 to 131929\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   business_id  131930 non-null  object\n",
      " 1   date         131930 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_checkin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id    0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el archivo no presenta valores nulos en ninguna de sus columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se corrobora que no haya filas duplicadas en la columna \"business_id\".\n",
    "duplicados = df_checkin['business_id'].duplicated()\n",
    "duplicados_df = df_checkin[duplicados]\n",
    "duplicados_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se observan datos duplicados en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 621 entries, 0 to 620\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   business_id  621 non-null    object\n",
      " 1   date         621 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_checkin_final = df_checkin[df_checkin['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_checkin_final = df_checkin_final.reset_index(drop=True, inplace=False)\n",
    "df_checkin_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"tip.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = [] \n",
    "#Se abre el archivo \"tip.json\".\n",
    "with open(path_tip, encoding=\"utf-8\") as archivo:\n",
    "    # EL bucle irá incorporando los datos a la lista.\n",
    "    for linea in archivo.readlines():\n",
    "        tip.append(ast.literal_eval(linea))\n",
    "\n",
    "#Se crea el dataframe \"df_tip\"\n",
    "df_tip = pd.DataFrame(tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>compliment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBN4MgHP9D3cw--SnauTkA</td>\n",
       "      <td>QoezRbYQncpRqyrLH6Iqjg</td>\n",
       "      <td>They have lots of good deserts and tasty cuban...</td>\n",
       "      <td>2013-02-05 18:35:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-copOvldyKh1qr-vzkDEvw</td>\n",
       "      <td>MYoRNLb5chwjQe3c_k37Gg</td>\n",
       "      <td>It's open even when you think it isn't</td>\n",
       "      <td>2013-08-18 00:56:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FjMQVZjSqY8syIO-53KFKw</td>\n",
       "      <td>hV-bABTK-glh5wj31ps_Jw</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "      <td>2017-06-27 23:05:38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n",
       "2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n",
       "3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n",
       "4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0                     Avengers time with the ladies.  2012-05-18 02:17:21   \n",
       "1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10   \n",
       "2             It's open even when you think it isn't  2013-08-18 00:56:08   \n",
       "3                          Very decent fried chicken  2017-06-27 23:05:38   \n",
       "4             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n",
       "\n",
       "   compliment_count  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908915 entries, 0 to 908914\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_id           908915 non-null  object\n",
      " 1   business_id       908915 non-null  object\n",
      " 2   text              908915 non-null  object\n",
      " 3   date              908915 non-null  object\n",
      " 4   compliment_count  908915 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 34.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tip.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             0\n",
       "business_id         0\n",
       "text                0\n",
       "date                0\n",
       "compliment_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tip.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el archivo no presenta valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corrobora que si hay filas duplicadas en base al contenido de las columnas \"user_id\", \"text\" y \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_duplicados = df_tip.duplicated(subset=['user_id', 'text', 'date'], keep=False)\n",
    "filas_valores_duplicados = df_tip[valores_duplicados]\n",
    "filas_valores_duplicados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas que poseen valores duplicados en las columnas \"user_id\", \"text\" y \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip = df_tip.drop_duplicates(subset=['user_id', 'text', 'date'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se verifica que se hayan realizado los cambios.\n",
    "valores_duplicados = df_tip.duplicated(subset=['user_id', 'text', 'date'], keep=False)\n",
    "filas_valores_duplicados = df_tip[valores_duplicados]\n",
    "filas_valores_duplicados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fecha mínima es 2009-04-16 13:11:49 y la fecha máxima es 2022-01-19 20:38:55\n"
     ]
    }
   ],
   "source": [
    "fecha_maxima = df_tip['date'].max()\n",
    "fecha_minima = df_tip['date'].min()\n",
    "\n",
    "print(f'La fecha mínima es {fecha_minima} y la fecha máxima es {fecha_maxima}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean columnas específicas para cada formato temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip['date'] = pd.to_datetime(df_tip['date'])\n",
    "\n",
    "# Se crea una nueva columna con la fecha en formato 'YYYY-MM-DD'.\n",
    "df_tip['fecha'] = df_tip['date'].dt.date\n",
    "\n",
    "# Se crea una nueva columna con la hora en formato de 24 horas enteras.\n",
    "df_tip['hora'] = df_tip['date'].dt.hour\n",
    "\n",
    "df_tip['dia_semana'] = df_tip['date'].dt.strftime('%A')\n",
    "\n",
    "# Se crea un diccionario para mapear los dias de la semana en español.\n",
    "dias_semana_es = {\n",
    "    'Monday': 'Lunes',\n",
    "    'Tuesday': 'Martes',\n",
    "    'Wednesday': 'Miércoles',\n",
    "    'Thursday': 'Jueves',\n",
    "    'Friday': 'Viernes',\n",
    "    'Saturday': 'Sábado',\n",
    "    'Sunday': 'Domingo'\n",
    "}\n",
    "df_tip['dia_semana'] = df_tip['dia_semana'].map(dias_semana_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>compliment_count</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>dia_semana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Viernes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "\n",
       "                             text                date  compliment_count  \\\n",
       "0  Avengers time with the ladies. 2012-05-18 02:17:21                 0   \n",
       "\n",
       "        fecha  hora dia_semana  \n",
       "0  2012-05-18     2    Viernes  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tip.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"compliment_count\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se oopta por eliminar la columna ya que no aporta datos relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip = df_tip.drop(['compliment_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>dia_semana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "      <td>2012-05-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Viernes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "\n",
       "                             text                date       fecha  hora  \\\n",
       "0  Avengers time with the ladies. 2012-05-18 02:17:21  2012-05-18     2   \n",
       "\n",
       "  dia_semana  \n",
       "0    Viernes  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tip.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24084 entries, 0 to 24083\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   user_id      24084 non-null  object        \n",
      " 1   business_id  24084 non-null  object        \n",
      " 2   text         24084 non-null  object        \n",
      " 3   date         24084 non-null  datetime64[ns]\n",
      " 4   fecha        24084 non-null  object        \n",
      " 5   hora         24084 non-null  int32         \n",
      " 6   dia_semana   24084 non-null  object        \n",
      "dtypes: datetime64[ns](1), int32(1), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Se seleccionan los registros correspondientes al rango temporal entre 2017 y 2021.\n",
    "df_tip_1 = df_tip[df_tip['date'].between('2017-01-01', '2021-12-31', inclusive='both')]\n",
    "# Se filtran los registros que corresponden al \"user_id\" a utilizar.\n",
    "df_tip_final = df_tip_1[df_tip_1['user_id'].isin(user_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_tidf_tip_final =df_tip_final.reset_index(drop=True, inplace=False)\n",
    "df_tidf_tip_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"user.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_parquet(path_user, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>friends</th>\n",
       "      <th>fans</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>Walker</td>\n",
       "      <td>585</td>\n",
       "      <td>2007-01-25 16:47:26</td>\n",
       "      <td>7217</td>\n",
       "      <td>1259</td>\n",
       "      <td>5994</td>\n",
       "      <td>2007</td>\n",
       "      <td>NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...</td>\n",
       "      <td>267</td>\n",
       "      <td>3.91</td>\n",
       "      <td>250</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>844</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>239</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>4333</td>\n",
       "      <td>2009-01-25 04:35:42</td>\n",
       "      <td>43091</td>\n",
       "      <td>13066</td>\n",
       "      <td>27281</td>\n",
       "      <td>2009,2010,2011,2012,2013,2014,2015,2016,2017,2...</td>\n",
       "      <td>ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...</td>\n",
       "      <td>3138</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1145</td>\n",
       "      <td>264</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>251</td>\n",
       "      <td>1847</td>\n",
       "      <td>7054</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>1521</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>Steph</td>\n",
       "      <td>665</td>\n",
       "      <td>2008-07-25 10:41:00</td>\n",
       "      <td>2086</td>\n",
       "      <td>1010</td>\n",
       "      <td>1003</td>\n",
       "      <td>2009,2010,2011,2012,2013</td>\n",
       "      <td>LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...</td>\n",
       "      <td>52</td>\n",
       "      <td>3.32</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>96</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id    name  review_count        yelping_since  useful  \\\n",
       "0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585  2007-01-25 16:47:26    7217   \n",
       "1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333  2009-01-25 04:35:42   43091   \n",
       "2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665  2008-07-25 10:41:00    2086   \n",
       "\n",
       "   funny   cool                                              elite  \\\n",
       "0   1259   5994                                               2007   \n",
       "1  13066  27281  2009,2010,2011,2012,2013,2014,2015,2016,2017,2...   \n",
       "2   1010   1003                           2009,2010,2011,2012,2013   \n",
       "\n",
       "                                             friends  fans  average_stars  \\\n",
       "0  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...   267           3.91   \n",
       "1  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  3138           3.74   \n",
       "2  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...    52           3.32   \n",
       "\n",
       "   compliment_hot  compliment_more  compliment_profile  compliment_cute  \\\n",
       "0             250               65                  55               56   \n",
       "1            1145              264                 184              157   \n",
       "2              89               13                  10               17   \n",
       "\n",
       "   compliment_list  compliment_note  compliment_plain  compliment_cool  \\\n",
       "0               18              232               844              467   \n",
       "1              251             1847              7054             3131   \n",
       "2                3               66                96              119   \n",
       "\n",
       "   compliment_funny  compliment_writer  compliment_photos  \n",
       "0               467                239                180  \n",
       "1              3131               1521               1946  \n",
       "2               119                 35                 18  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2105597 entries, 0 to 2105596\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   user_id             object \n",
      " 1   name                object \n",
      " 2   review_count        int64  \n",
      " 3   yelping_since       object \n",
      " 4   useful              int64  \n",
      " 5   funny               int64  \n",
      " 6   cool                int64  \n",
      " 7   elite               object \n",
      " 8   friends             object \n",
      " 9   fans                int64  \n",
      " 10  average_stars       float64\n",
      " 11  compliment_hot      int64  \n",
      " 12  compliment_more     int64  \n",
      " 13  compliment_profile  int64  \n",
      " 14  compliment_cute     int64  \n",
      " 15  compliment_list     int64  \n",
      " 16  compliment_note     int64  \n",
      " 17  compliment_plain    int64  \n",
      " 18  compliment_cool     int64  \n",
      " 19  compliment_funny    int64  \n",
      " 20  compliment_writer   int64  \n",
      " 21  compliment_photos   int64  \n",
      "dtypes: float64(1), int64(16), object(5)\n",
      "memory usage: 353.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id               0\n",
       "name                  0\n",
       "review_count          0\n",
       "yelping_since         0\n",
       "useful                0\n",
       "funny                 0\n",
       "cool                  0\n",
       "elite                 0\n",
       "friends               0\n",
       "fans                  0\n",
       "average_stars         0\n",
       "compliment_hot        0\n",
       "compliment_more       0\n",
       "compliment_profile    0\n",
       "compliment_cute       0\n",
       "compliment_list       0\n",
       "compliment_note       0\n",
       "compliment_plain      0\n",
       "compliment_cool       0\n",
       "compliment_funny      0\n",
       "compliment_writer     0\n",
       "compliment_photos     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117700, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados = df_user['user_id'].duplicated()\n",
    "duplicados_user = df_user[duplicados]\n",
    "duplicados_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en el dataset hay 117700 filas duplicadas las cuales serán eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user.drop_duplicates(keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados = df_user['user_id'].duplicated()\n",
    "duplicados_user = df_user[duplicados]\n",
    "duplicados_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se opta por eliminar las columnas   ya que no aportan valor al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user.drop(columns=['elite','compliment_hot', 'compliment_more','compliment_profile','compliment_cute','compliment_list','compliment_note',\n",
    "                                'compliment_plain','compliment_cool','compliment_funny','compliment_writer','compliment_photos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>friends</th>\n",
       "      <th>fans</th>\n",
       "      <th>average_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>Walker</td>\n",
       "      <td>585</td>\n",
       "      <td>2007-01-25 16:47:26</td>\n",
       "      <td>7217</td>\n",
       "      <td>1259</td>\n",
       "      <td>5994</td>\n",
       "      <td>NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...</td>\n",
       "      <td>267</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>4333</td>\n",
       "      <td>2009-01-25 04:35:42</td>\n",
       "      <td>43091</td>\n",
       "      <td>13066</td>\n",
       "      <td>27281</td>\n",
       "      <td>ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...</td>\n",
       "      <td>3138</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>Steph</td>\n",
       "      <td>665</td>\n",
       "      <td>2008-07-25 10:41:00</td>\n",
       "      <td>2086</td>\n",
       "      <td>1010</td>\n",
       "      <td>1003</td>\n",
       "      <td>LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...</td>\n",
       "      <td>52</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id    name  review_count        yelping_since  useful  \\\n",
       "0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585  2007-01-25 16:47:26    7217   \n",
       "1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333  2009-01-25 04:35:42   43091   \n",
       "2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665  2008-07-25 10:41:00    2086   \n",
       "\n",
       "   funny   cool                                            friends  fans  \\\n",
       "0   1259   5994  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...   267   \n",
       "1  13066  27281  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  3138   \n",
       "2   1010   1003  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...    52   \n",
       "\n",
       "   average_stars  \n",
       "0           3.91  \n",
       "1           3.74  \n",
       "2           3.32  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia el tipo de dato de las distintas columnas para reducir el peso del archivo y mejorar su procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['review_count'] = df_user['review_count'].astype('int16')\n",
    "df_user['useful'] = df_user['useful'].astype('int32')\n",
    "df_user['funny'] = df_user['funny'].astype('int32')\n",
    "df_user['cool'] = df_user['cool'].astype('int32')\n",
    "df_user['fans'] = df_user['fans'].astype('int16')\n",
    "df_user['average_stars'] = df_user['average_stars'].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1987897 entries, 0 to 1987896\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   user_id        object \n",
      " 1   name           object \n",
      " 2   review_count   int16  \n",
      " 3   yelping_since  object \n",
      " 4   useful         int32  \n",
      " 5   funny          int32  \n",
      " 6   cool           int32  \n",
      " 7   friends        object \n",
      " 8   fans           int16  \n",
      " 9   average_stars  float16\n",
      "dtypes: float16(1), int16(2), int32(3), object(4)\n",
      "memory usage: 110.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31344 entries, 0 to 31343\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   user_id        31344 non-null  object \n",
      " 1   name           31344 non-null  object \n",
      " 2   review_count   31344 non-null  int16  \n",
      " 3   yelping_since  31344 non-null  object \n",
      " 4   useful         31344 non-null  int32  \n",
      " 5   funny          31344 non-null  int32  \n",
      " 6   cool           31344 non-null  int32  \n",
      " 7   friends        31344 non-null  object \n",
      " 8   fans           31344 non-null  int16  \n",
      " 9   average_stars  31344 non-null  float16\n",
      "dtypes: float16(1), int16(2), int32(3), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_user_final = df_user[df_user['user_id'].isin(user_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_user_final = df_user_final.reset_index(drop=True, inplace=False)\n",
    "df_user_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a complicaciones con el tamaño del archivo se opta por generar una muestra del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   user_id        20000 non-null  object \n",
      " 1   name           20000 non-null  object \n",
      " 2   review_count   20000 non-null  int16  \n",
      " 3   yelping_since  20000 non-null  object \n",
      " 4   useful         20000 non-null  int32  \n",
      " 5   funny          20000 non-null  int32  \n",
      " 6   cool           20000 non-null  int32  \n",
      " 7   friends        20000 non-null  object \n",
      " 8   fans           20000 non-null  int16  \n",
      " 9   average_stars  20000 non-null  float16\n",
      "dtypes: float16(1), int16(2), int32(3), object(4)\n",
      "memory usage: 976.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_user_final = df_user_final.sample(n=20000, random_state=42)\n",
    "df_user_final = df_user_final.reset_index(drop=True, inplace=False)\n",
    "df_user_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean archivos en formato parquet en base a los datasets que se fueron trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo \"business.parquet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df_business_final)\n",
    "pq.write_table(table, 'business.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo \"review.parquet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df_review_final)\n",
    "pq.write_table(table, 'review.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo \"checkin.parquet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df_checkin_final)\n",
    "pq.write_table(table, 'checkin.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo \"tip.parquet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df_tip_final)\n",
    "pq.write_table(table, 'tip.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo \"user.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df_user_final)\n",
    "pq.write_table(table, 'user.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
