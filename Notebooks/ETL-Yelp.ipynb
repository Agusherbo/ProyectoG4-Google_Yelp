{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL - YELP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Se configura pandas para que se muestre la totalidad de las columnas del dataframe.\n",
    "pd.options.display.max_columns = None\n",
    "import ast\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutas a los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_buisness = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\business.pkl'\n",
    "path_checkin = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\checkin.json'\n",
    "path_review = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.json'\n",
    "path_review_parquet = \"C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.parquet\"\n",
    "path_tip = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\tip.json'\n",
    "path_user = 'C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\user.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"business.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = pd.read_pickle(path_buisness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>CA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
       "\n",
       "                           address           city state postal_code  \\\n",
       "0           1616 Chapala St, Ste 2  Santa Barbara   NaN       93101   \n",
       "1  87 Grasso Plaza Shopping Center         Affton   NaN       63123   \n",
       "2             5255 E Broadway Blvd         Tucson   NaN       85711   \n",
       "3                      935 Race St   Philadelphia    CA       19107   \n",
       "\n",
       "    latitude   longitude stars review_count is_open  \\\n",
       "0  34.426679 -119.711197   5.0            7       0   \n",
       "1  38.551126  -90.335695   3.0           15       1   \n",
       "2  32.223236 -110.880452   3.5           22       0   \n",
       "3  39.955505  -75.155564   4.0           80       1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                      {'ByAppointmentOnly': 'True'}   \n",
       "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
       "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2  Department Stores, Shopping, Fashion, Home & G...   \n",
       "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "\n",
       "                                               hours business_id name address  \\\n",
       "0                                               None         NaN  NaN     NaN   \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...         NaN  NaN     NaN   \n",
       "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...         NaN  NaN     NaN   \n",
       "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...         NaN  NaN     NaN   \n",
       "\n",
       "  city state postal_code latitude longitude stars review_count is_open  \\\n",
       "0  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "1  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "2  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "3  NaN   NaN         NaN      NaN       NaN   NaN          NaN     NaN   \n",
       "\n",
       "  attributes categories hours  \n",
       "0        NaN        NaN   NaN  \n",
       "1        NaN        NaN   NaN  \n",
       "2        NaN        NaN   NaN  \n",
       "3        NaN        NaN   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150346 entries, 0 to 150345\n",
      "Data columns (total 28 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   business_id   150346 non-null  object\n",
      " 1   name          150346 non-null  object\n",
      " 2   address       150346 non-null  object\n",
      " 3   city          150346 non-null  object\n",
      " 4   state         150343 non-null  object\n",
      " 5   postal_code   150346 non-null  object\n",
      " 6   latitude      150346 non-null  object\n",
      " 7   longitude     150346 non-null  object\n",
      " 8   stars         150346 non-null  object\n",
      " 9   review_count  150346 non-null  object\n",
      " 10  is_open       150346 non-null  object\n",
      " 11  attributes    136602 non-null  object\n",
      " 12  categories    150243 non-null  object\n",
      " 13  hours         127123 non-null  object\n",
      " 14  business_id   5 non-null       object\n",
      " 15  name          5 non-null       object\n",
      " 16  address       5 non-null       object\n",
      " 17  city          5 non-null       object\n",
      " 18  state         5 non-null       object\n",
      " 19  postal_code   5 non-null       object\n",
      " 20  latitude      5 non-null       object\n",
      " 21  longitude     5 non-null       object\n",
      " 22  stars         5 non-null       object\n",
      " 23  review_count  5 non-null       object\n",
      " 24  is_open       5 non-null       object\n",
      " 25  attributes    5 non-null       object\n",
      " 26  categories    5 non-null       object\n",
      " 27  hours         5 non-null       object\n",
      "dtypes: object(28)\n",
      "memory usage: 33.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id          0\n",
       "name                 0\n",
       "address              0\n",
       "city                 0\n",
       "state                3\n",
       "postal_code          0\n",
       "latitude             0\n",
       "longitude            0\n",
       "stars                0\n",
       "review_count         0\n",
       "is_open              0\n",
       "attributes       13744\n",
       "categories         103\n",
       "hours            23223\n",
       "business_id     150341\n",
       "name            150341\n",
       "address         150341\n",
       "city            150341\n",
       "state           150341\n",
       "postal_code     150341\n",
       "latitude        150341\n",
       "longitude       150341\n",
       "stars           150341\n",
       "review_count    150341\n",
       "is_open         150341\n",
       "attributes      150341\n",
       "categories      150341\n",
       "hours           150341\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar la existencia de columnas duplicadas cuyo contenido está compuesto en su mayor parte de valores nulos se procede a eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business.loc[:, ~df_business.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corrobora que se hayan efectuado los cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id         0\n",
       "name                0\n",
       "address             0\n",
       "city                0\n",
       "state               3\n",
       "postal_code         0\n",
       "latitude            0\n",
       "longitude           0\n",
       "stars               0\n",
       "review_count        0\n",
       "is_open             0\n",
       "attributes      13744\n",
       "categories        103\n",
       "hours           23223\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"business_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados_business = df_business['business_id'].duplicated()\n",
    "df_duplicados_business = df_business[duplicados_business]\n",
    "df_duplicados_business.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna \"business_id\" no presenta valores duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas \"categories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de categorías únicas es1311\n"
     ]
    }
   ],
   "source": [
    "categories_lists = df_business['categories'].str.split(', ')\n",
    "\n",
    "# Apilar todas las listas resultantes en una sola lista\n",
    "all_categories = [category for sublist in categories_lists if sublist is not None for category in sublist]\n",
    "\n",
    "# Obtener los valores únicos de la lista\n",
    "unique_categories = set(all_categories)\n",
    "print(f'La cantidad de categorías únicas es{len(unique_categories)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el dataframe \"df_restaurants\" en base a las filas que contienen el valor \"restaurant\" dentro de ellas con el objetivo de reducir la cantidad de filas a solo las que serán utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_restaurant = df_business['categories'].str.contains('restaurant', case=False, na=False)\n",
    "df_restaurants = df_business[filtro_restaurant]\n",
    "df_restaurants = df_restaurants.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52286 entries, 0 to 52285\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   business_id   52286 non-null  object\n",
      " 1   name          52286 non-null  object\n",
      " 2   address       52286 non-null  object\n",
      " 3   city          52286 non-null  object\n",
      " 4   state         52286 non-null  object\n",
      " 5   postal_code   52286 non-null  object\n",
      " 6   latitude      52286 non-null  object\n",
      " 7   longitude     52286 non-null  object\n",
      " 8   stars         52286 non-null  object\n",
      " 9   review_count  52286 non-null  object\n",
      " 10  is_open       52286 non-null  object\n",
      " 11  attributes    51720 non-null  object\n",
      " 12  categories    52286 non-null  object\n",
      " 13  hours         45007 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_restaurants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"state\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de valores nulos presente en la columna \"state\" es 3.\n"
     ]
    }
   ],
   "source": [
    "nulos_estado = df_business['state'].isnull().sum()\n",
    "print(f'La cantidad de valores nulos presente en la columna \"state\" es {nulos_estado}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la imputación de valores faltantes de la columna \"state\" con ayuda del valor más frecuente de la columna \"postal_code\" para el estado correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera una función lambda que será utilizada en la función de imputación.\n",
    "imputacion_dict = df_restaurants.groupby('postal_code')['state'].apply(lambda x: x.mode()[0] if not x.mode().empty else None).to_dict()\n",
    "\n",
    "# Se crea una función para llevar a cabo la imputación de datos.\n",
    "def imputar_estado(row):\n",
    "    if pd.isnull(row['state']):\n",
    "        return imputacion_dict.get(row['postal_code'], row['state'])\n",
    "    else:\n",
    "        return row['state']\n",
    "\n",
    "# Se aplica la función a cada fila del DataFrame.\n",
    "df_restaurants['state'] = df_restaurants.apply(imputar_estado, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de valores nulos presente en la columna \"state\" es 0.\n"
     ]
    }
   ],
   "source": [
    "nulos_estado = df_restaurants['state'].isnull().sum()\n",
    "print(f'La cantidad de valores nulos presente en la columna \"state\" es {nulos_estado}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de estados es: 21. Éstos siendo CA, AZ, TN, MO, FL, IN, LA, PA, AB, ID, IL, NJ, NV, DE, CO, WA, HI, TX, MI, VI, VT\n"
     ]
    }
   ],
   "source": [
    "valores_unicos_estado = df_restaurants['state'].unique()\n",
    "estados_unicos = ', '.join(valores_unicos_estado)\n",
    "conteo_estados = df_restaurants['state'].nunique()\n",
    "print(f'La cantidad de estados es: {conteo_estados}. Éstos siendo {estados_unicos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Al haberse realizado una reducción de los datos a través del dataframe \"df_restaurants\" se usará los datos de la columna \"business_id\" para descartar las filas de los demás datasets que no coincidan con dicho ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids = df_restaurants['business_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"checkin.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin = []\n",
    "\n",
    "with open(path_checkin, 'r') as archivo:\n",
    "    #Se crea un loop para ir incorporando los elementos a la lista.\n",
    "    for linea in archivo:\n",
    "        data= json.loads(linea)\n",
    "        checkin.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--0iUa4sNDFiZFrAdIWhZQ</td>\n",
       "      <td>2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--30_8IhuyMHbSOcNWd6DQ</td>\n",
       "      <td>2013-06-14 23:29:17, 2014-08-13 23:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--7jw19RH9JKXgFohspgQw</td>\n",
       "      <td>2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131925</th>\n",
       "      <td>zznJox6-nmXlGYNWgTDwQQ</td>\n",
       "      <td>2013-03-23 16:22:47, 2013-04-07 02:03:12, 2013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131926</th>\n",
       "      <td>zznZqH9CiAznbkV6fXyHWA</td>\n",
       "      <td>2021-06-12 01:16:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131927</th>\n",
       "      <td>zzu6_r3DxBJuXcjnOYVdTw</td>\n",
       "      <td>2011-05-24 01:35:13, 2012-01-01 23:44:33, 2012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131928</th>\n",
       "      <td>zzw66H6hVjXQEt0Js3Mo4A</td>\n",
       "      <td>2016-12-03 23:33:26, 2018-12-02 19:08:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131929</th>\n",
       "      <td>zzyx5x0Z7xXWWvWnZFuxlQ</td>\n",
       "      <td>2015-01-06 17:51:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131930 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "0       ---kPU91CF4Lq2-WlRu9Lw   \n",
       "1       --0iUa4sNDFiZFrAdIWhZQ   \n",
       "2       --30_8IhuyMHbSOcNWd6DQ   \n",
       "3       --7PUidqRWpRSpXebiyxTg   \n",
       "4       --7jw19RH9JKXgFohspgQw   \n",
       "...                        ...   \n",
       "131925  zznJox6-nmXlGYNWgTDwQQ   \n",
       "131926  zznZqH9CiAznbkV6fXyHWA   \n",
       "131927  zzu6_r3DxBJuXcjnOYVdTw   \n",
       "131928  zzw66H6hVjXQEt0Js3Mo4A   \n",
       "131929  zzyx5x0Z7xXWWvWnZFuxlQ   \n",
       "\n",
       "                                                     date  \n",
       "0       2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...  \n",
       "1       2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...  \n",
       "2                2013-06-14 23:29:17, 2014-08-13 23:20:22  \n",
       "3       2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...  \n",
       "4       2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...  \n",
       "...                                                   ...  \n",
       "131925  2013-03-23 16:22:47, 2013-04-07 02:03:12, 2013...  \n",
       "131926                                2021-06-12 01:16:12  \n",
       "131927  2011-05-24 01:35:13, 2012-01-01 23:44:33, 2012...  \n",
       "131928           2016-12-03 23:33:26, 2018-12-02 19:08:45  \n",
       "131929                                2015-01-06 17:51:53  \n",
       "\n",
       "[131930 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkin = pd.DataFrame(checkin)\n",
    "df_checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131930 entries, 0 to 131929\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   business_id  131930 non-null  object\n",
      " 1   date         131930 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_checkin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id    0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkin.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el archivo no presenta valores nulos en ninguna de sus columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se corrobora que no haya filas duplicadas en la columna \"business_id\".\n",
    "duplicados = df_checkin['business_id'].duplicated()\n",
    "duplicados_df = df_checkin[duplicados]\n",
    "duplicados_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131930 entries, 0 to 131929\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   index        131930 non-null  int64 \n",
      " 1   business_id  131930 non-null  object\n",
      " 2   date         131930 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_checkin_final = df_checkin[df_checkin['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_checkin_final = df_checkin.reset_index(drop=False, inplace=False)\n",
    "df_checkin_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"review.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extraen los datos del archivo \"review.json\" para pasarlo a formato parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = \"C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.json\"\n",
    "path_review_parquet = \"C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Raw\\\\review.parquet\"\n",
    "\n",
    "# Se lee el archivo json en fragmentos para manejar archivos grandes\n",
    "chunksize = 100000  # Número de líneas por fragmento\n",
    "chunks = pd.read_json(path_review, lines=True, chunksize=chunksize)\n",
    "\n",
    "# Se crea una lista para almacenar las tablas PyArrow\n",
    "tables = []\n",
    "\n",
    "# Se procesa cada fragmento y convertirlo en una tabla PyArrow\n",
    "for chunk in chunks:\n",
    "    table = pa.Table.from_pandas(chunk)\n",
    "    tables.append(table)\n",
    "\n",
    "# Concatenar todas las tablas en una sola tabla\n",
    "final_table = pa.concat_tables(tables)\n",
    "\n",
    "# Guardar la tabla final en un archivo Parquet\n",
    "pq.write_table(final_table, path_review_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lote 1 guardado como review_0.parquet\n",
      "Lote 2 guardado como review_1.parquet\n",
      "Lote 3 guardado como review_2.parquet\n",
      "Lote 4 guardado como review_3.parquet\n",
      "Lote 5 guardado como review_4.parquet\n",
      "Lote 6 guardado como review_5.parquet\n",
      "Lote 7 guardado como review_6.parquet\n",
      "Proceso completo.\n"
     ]
    }
   ],
   "source": [
    "# Especificamos el tamaño del trozo que queremos leer y guardar\n",
    "chunksize = 1000000  # 1 millón de filas por trozo\n",
    "\n",
    "# Abre el archivo Parquet\n",
    "parquet_file = pq.ParquetFile(path_review_parquet)\n",
    "\n",
    "# Obtén el número total de grupos de filas en el archivo Parquet\n",
    "total_row_groups = parquet_file.num_row_groups\n",
    "\n",
    "# Itera sobre el archivo Parquet y guarda cada trozo como un archivo Parquet\n",
    "for i in range(0, total_row_groups):\n",
    "    # Lee un trozo del archivo Parquet\n",
    "    lote = parquet_file.read_row_group(i, use_pandas_metadata=True).to_pandas()\n",
    "\n",
    "    # Guarda el trozo como un archivo Parquet\n",
    "    lote.to_parquet(f\"review_{i}.parquet\", index=False)\n",
    "\n",
    "    # mensaje de procesos completados por archivo\n",
    "    print(f\"Lote {i + 1} guardado como review_{i}.parquet\")\n",
    "\n",
    "print(\"Proceso completo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_0 = pd.read_parquet('C:\\\\Users\\\\fedez\\\\OneDrive\\\\Escritorio\\\\ProyectoG4-Google_Yelp\\\\Data\\\\Processed\\\\review_0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text                date  \n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "user_id        0\n",
       "business_id    0\n",
       "stars          0\n",
       "useful         0\n",
       "funny          0\n",
       "cool           0\n",
       "text           0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_0.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"tip.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip = [] \n",
    "#Se abre el archivo \"tip.json\".\n",
    "with open(path_tip, encoding=\"utf-8\") as archivo:\n",
    "    # EL bucle irá incorporando los datos a la lista.\n",
    "    for linea in archivo.readlines():\n",
    "        tip.append(ast.literal_eval(linea))\n",
    "\n",
    "#Se crea el dataframe \"df_tip\"\n",
    "df_tip = pd.DataFrame(tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>compliment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBN4MgHP9D3cw--SnauTkA</td>\n",
       "      <td>QoezRbYQncpRqyrLH6Iqjg</td>\n",
       "      <td>They have lots of good deserts and tasty cuban...</td>\n",
       "      <td>2013-02-05 18:35:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-copOvldyKh1qr-vzkDEvw</td>\n",
       "      <td>MYoRNLb5chwjQe3c_k37Gg</td>\n",
       "      <td>It's open even when you think it isn't</td>\n",
       "      <td>2013-08-18 00:56:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FjMQVZjSqY8syIO-53KFKw</td>\n",
       "      <td>hV-bABTK-glh5wj31ps_Jw</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "      <td>2017-06-27 23:05:38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n",
       "2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n",
       "3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n",
       "4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0                     Avengers time with the ladies.  2012-05-18 02:17:21   \n",
       "1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10   \n",
       "2             It's open even when you think it isn't  2013-08-18 00:56:08   \n",
       "3                          Very decent fried chicken  2017-06-27 23:05:38   \n",
       "4             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n",
       "\n",
       "   compliment_count  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908915 entries, 0 to 908914\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_id           908915 non-null  object\n",
      " 1   business_id       908915 non-null  object\n",
      " 2   text              908915 non-null  object\n",
      " 3   date              908915 non-null  object\n",
      " 4   compliment_count  908915 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 34.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tip.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             0\n",
       "business_id         0\n",
       "text                0\n",
       "date                0\n",
       "compliment_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tip.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el archivo no presenta valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corrobora que si hay filas duplicadas en base al contenido de las columnas \"user_id\", \"text\" y \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_duplicados = df_tip.duplicated(subset=['user_id', 'text', 'date'], keep=False)\n",
    "filas_valores_duplicados = df_tip[valores_duplicados]\n",
    "filas_valores_duplicados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas que poseen valores duplicados en las columnas \"user_id\", \"text\" y \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip = df_tip.drop_duplicates(subset=['user_id', 'text', 'date'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se verifica que se hayan realizado los cambios.\n",
    "valores_duplicados = df_tip.duplicated(subset=['user_id', 'text', 'date'], keep=False)\n",
    "filas_valores_duplicados = df_tip[valores_duplicados]\n",
    "filas_valores_duplicados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna \"date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fecha mínima es 2009-04-16 13:11:49 y la fecha máxima es 2022-01-19 20:38:55\n"
     ]
    }
   ],
   "source": [
    "fecha_maxima = df_tip['date'].max()\n",
    "fecha_minima = df_tip['date'].min()\n",
    "\n",
    "print(f'La fecha mínima es {fecha_minima} y la fecha máxima es {fecha_maxima}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908848 entries, 0 to 908847\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   index             908848 non-null  int64 \n",
      " 1   user_id           908848 non-null  object\n",
      " 2   business_id       908848 non-null  object\n",
      " 3   text              908848 non-null  object\n",
      " 4   date              908848 non-null  object\n",
      " 5   compliment_count  908848 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 41.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Se filtran las filas que no contengan los \"business_ids\" correspondientes.\n",
    "df_tip_final = df_tip[df_tip['business_id'].isin(business_ids)]\n",
    "# Se realiza el reset del índice.\n",
    "df_tip_final = df_tip.reset_index(drop=False, inplace=False)\n",
    "df_tip_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo \"user.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_parquet(path_user, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>friends</th>\n",
       "      <th>fans</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>Walker</td>\n",
       "      <td>585</td>\n",
       "      <td>2007-01-25 16:47:26</td>\n",
       "      <td>7217</td>\n",
       "      <td>1259</td>\n",
       "      <td>5994</td>\n",
       "      <td>2007</td>\n",
       "      <td>NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...</td>\n",
       "      <td>267</td>\n",
       "      <td>3.91</td>\n",
       "      <td>250</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>844</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>239</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>4333</td>\n",
       "      <td>2009-01-25 04:35:42</td>\n",
       "      <td>43091</td>\n",
       "      <td>13066</td>\n",
       "      <td>27281</td>\n",
       "      <td>2009,2010,2011,2012,2013,2014,2015,2016,2017,2...</td>\n",
       "      <td>ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...</td>\n",
       "      <td>3138</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1145</td>\n",
       "      <td>264</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>251</td>\n",
       "      <td>1847</td>\n",
       "      <td>7054</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>1521</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>Steph</td>\n",
       "      <td>665</td>\n",
       "      <td>2008-07-25 10:41:00</td>\n",
       "      <td>2086</td>\n",
       "      <td>1010</td>\n",
       "      <td>1003</td>\n",
       "      <td>2009,2010,2011,2012,2013</td>\n",
       "      <td>LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...</td>\n",
       "      <td>52</td>\n",
       "      <td>3.32</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>96</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SZDeASXq7o05mMNLshsdIA</td>\n",
       "      <td>Gwen</td>\n",
       "      <td>224</td>\n",
       "      <td>2005-11-29 04:38:33</td>\n",
       "      <td>512</td>\n",
       "      <td>330</td>\n",
       "      <td>299</td>\n",
       "      <td>2009,2010,2011</td>\n",
       "      <td>enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...</td>\n",
       "      <td>28</td>\n",
       "      <td>4.27</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hA5lMy-EnncsH4JoR-hFGQ</td>\n",
       "      <td>Karen</td>\n",
       "      <td>79</td>\n",
       "      <td>2007-01-05 19:40:59</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id    name  review_count        yelping_since  useful  \\\n",
       "0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585  2007-01-25 16:47:26    7217   \n",
       "1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333  2009-01-25 04:35:42   43091   \n",
       "2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665  2008-07-25 10:41:00    2086   \n",
       "3  SZDeASXq7o05mMNLshsdIA    Gwen           224  2005-11-29 04:38:33     512   \n",
       "4  hA5lMy-EnncsH4JoR-hFGQ   Karen            79  2007-01-05 19:40:59      29   \n",
       "\n",
       "   funny   cool                                              elite  \\\n",
       "0   1259   5994                                               2007   \n",
       "1  13066  27281  2009,2010,2011,2012,2013,2014,2015,2016,2017,2...   \n",
       "2   1010   1003                           2009,2010,2011,2012,2013   \n",
       "3    330    299                                     2009,2010,2011   \n",
       "4     15      7                                                      \n",
       "\n",
       "                                             friends  fans  average_stars  \\\n",
       "0  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...   267           3.91   \n",
       "1  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  3138           3.74   \n",
       "2  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...    52           3.32   \n",
       "3  enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...    28           4.27   \n",
       "4  PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...     1           3.54   \n",
       "\n",
       "   compliment_hot  compliment_more  compliment_profile  compliment_cute  \\\n",
       "0             250               65                  55               56   \n",
       "1            1145              264                 184              157   \n",
       "2              89               13                  10               17   \n",
       "3              24                4                   1                6   \n",
       "4               1                1                   0                0   \n",
       "\n",
       "   compliment_list  compliment_note  compliment_plain  compliment_cool  \\\n",
       "0               18              232               844              467   \n",
       "1              251             1847              7054             3131   \n",
       "2                3               66                96              119   \n",
       "3                2               12                16               26   \n",
       "4                0                1                 1                0   \n",
       "\n",
       "   compliment_funny  compliment_writer  compliment_photos  \n",
       "0               467                239                180  \n",
       "1              3131               1521               1946  \n",
       "2               119                 35                 18  \n",
       "3                26                 10                  9  \n",
       "4                 0                  0                  0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1987897 entries, 0 to 1987896\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   user_id             object \n",
      " 1   name                object \n",
      " 2   review_count        int64  \n",
      " 3   yelping_since       object \n",
      " 4   useful              int64  \n",
      " 5   funny               int64  \n",
      " 6   cool                int64  \n",
      " 7   elite               object \n",
      " 8   friends             object \n",
      " 9   fans                int64  \n",
      " 10  average_stars       float64\n",
      " 11  compliment_hot      int64  \n",
      " 12  compliment_more     int64  \n",
      " 13  compliment_profile  int64  \n",
      " 14  compliment_cute     int64  \n",
      " 15  compliment_list     int64  \n",
      " 16  compliment_note     int64  \n",
      " 17  compliment_plain    int64  \n",
      " 18  compliment_cool     int64  \n",
      " 19  compliment_funny    int64  \n",
      " 20  compliment_writer   int64  \n",
      " 21  compliment_photos   int64  \n",
      "dtypes: float64(1), int64(16), object(5)\n",
      "memory usage: 348.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id               0\n",
       "name                  0\n",
       "review_count          0\n",
       "yelping_since         0\n",
       "useful                0\n",
       "funny                 0\n",
       "cool                  0\n",
       "elite                 0\n",
       "friends               0\n",
       "fans                  0\n",
       "average_stars         0\n",
       "compliment_hot        0\n",
       "compliment_more       0\n",
       "compliment_profile    0\n",
       "compliment_cute       0\n",
       "compliment_list       0\n",
       "compliment_note       0\n",
       "compliment_plain      0\n",
       "compliment_cool       0\n",
       "compliment_funny      0\n",
       "compliment_writer     0\n",
       "compliment_photos     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117700, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados = df_user['user_id'].duplicated()\n",
    "duplicados_user = df_user[duplicados]\n",
    "duplicados_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en el dataset hay 117700 filas duplicadas las cuales serán eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user.drop_duplicates(keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 22)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados = df_user['user_id'].duplicated()\n",
    "duplicados_user = df_user[duplicados]\n",
    "duplicados_user.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
