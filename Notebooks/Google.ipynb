{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\dask\\dataframe\\__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importamos las librerias que usaremos\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import dask.dataframe as dd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata sitios\n",
    "A continuacion se realizara la union de los distintos data sets de los datos de negocios y se filtraran por la categoria de restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_entrada = '../Data/Data_limpia/Google/Metadata'\n",
    "ruta_salida = '../Data/Data_transformada/Metadata'\n",
    "\n",
    "# Creamos una lista vacia que va a almacenar todos los data frames \n",
    "dfs = []\n",
    "\n",
    "        # Iteramos la carpeta para leer los archivos\n",
    "for item in os.listdir(ruta_entrada):\n",
    "     # Verificamos que sea un archivo JSON y guardamos su ruta\n",
    "    if item.endswith('.json'):\n",
    "        path_item = os.path.join(ruta_entrada,item)\n",
    "\n",
    "        # Leemos el archivo JSON\n",
    "        df = pd.read_json(path_item, lines = True)\n",
    "\n",
    "        # Añadimos el DF a la lista de DFS\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenamos los dataframes para tener un archivo unico      \n",
    "df_combinado = pd.concat(dfs) \n",
    "\n",
    "# Definimos la ruta de salida\n",
    "salida = os.path.join(ruta_salida, 'Sitios_combinada.parquet')\n",
    "\n",
    "# Guardamos el data frame en formato parquet\n",
    "df_combinado.to_parquet(salida, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo de forma porcionada ya que es un data set muy grande\n",
    "df = dd.read_parquet('../Data/Data_transformada/Metadata/Sitios_combinada.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>hours</th>\n",
       "      <th>MISC</th>\n",
       "      <th>state</th>\n",
       "      <th>relative_results</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Porter Pharmacy</td>\n",
       "      <td>Porter Pharmacy, 129 N Second St, Cochran, GA ...</td>\n",
       "      <td>0x88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>32.388300</td>\n",
       "      <td>-83.357100</td>\n",
       "      <td>[Pharmacy]</td>\n",
       "      <td>4.9</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[[Friday, 8AM–6PM], [Saturday, 8AM–12PM], [Sun...</td>\n",
       "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
       "      <td>Open ⋅ Closes 6PM</td>\n",
       "      <td>[0x88f16e41929435cf:0x5b2532a2885e9ef6, 0x88f1...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Textile</td>\n",
       "      <td>City Textile, 3001 E Pico Blvd, Los Angeles, C...</td>\n",
       "      <td>0x80c2c98c0e3c16fd:0x29ec8a728764fdf9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>34.018891</td>\n",
       "      <td>-118.215290</td>\n",
       "      <td>[Textile exporter]</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Open now</td>\n",
       "      <td>[0x80c2c624136ea88b:0xb0315367ed448771, 0x80c2...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Soo Dang</td>\n",
       "      <td>San Soo Dang, 761 S Vermont Ave, Los Angeles, ...</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>34.058092</td>\n",
       "      <td>-118.292130</td>\n",
       "      <td>[Korean restaurant]</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[[Thursday, 6:30AM–6PM], [Friday, 6:30AM–6PM],...</td>\n",
       "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
       "      <td>Open ⋅ Closes 6PM</td>\n",
       "      <td>[0x80c2c78249aba68f:0x35bf16ce61be751d, 0x80c2...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nova Fabrics</td>\n",
       "      <td>Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...</td>\n",
       "      <td>0x80c2c89923b27a41:0x32041559418d447</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>34.023669</td>\n",
       "      <td>-118.232930</td>\n",
       "      <td>[Fabric store]</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[[Thursday, 9AM–5PM], [Friday, 9AM–5PM], [Satu...</td>\n",
       "      <td>{'Accessibility': None, 'Activities': None, 'A...</td>\n",
       "      <td>Open ⋅ Closes 5PM</td>\n",
       "      <td>[0x80c2c8811477253f:0x23a8a492df1918f7, 0x80c2...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nobel Textile Co</td>\n",
       "      <td>Nobel Textile Co, 719 E 9th St, Los Angeles, C...</td>\n",
       "      <td>0x80c2c632f933b073:0xc31785961fe826a6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>34.036694</td>\n",
       "      <td>-118.249421</td>\n",
       "      <td>[Fabric store]</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[[Thursday, 9AM–5PM], [Friday, 9AM–5PM], [Satu...</td>\n",
       "      <td>{'Accessibility': None, 'Activities': None, 'A...</td>\n",
       "      <td>Open ⋅ Closes 5PM</td>\n",
       "      <td>[0x80c2c62c496083d1:0xdefa11317fe870a1, 0x80c2...</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                            address  \\\n",
       "0   Porter Pharmacy  Porter Pharmacy, 129 N Second St, Cochran, GA ...   \n",
       "1      City Textile  City Textile, 3001 E Pico Blvd, Los Angeles, C...   \n",
       "2      San Soo Dang  San Soo Dang, 761 S Vermont Ave, Los Angeles, ...   \n",
       "3      Nova Fabrics  Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...   \n",
       "4  Nobel Textile Co  Nobel Textile Co, 719 E 9th St, Los Angeles, C...   \n",
       "\n",
       "                                 gmap_id description   latitude   longitude  \\\n",
       "0  0x88f16e41928ff687:0x883dad4fd048e8f8        <NA>  32.388300  -83.357100   \n",
       "1  0x80c2c98c0e3c16fd:0x29ec8a728764fdf9        <NA>  34.018891 -118.215290   \n",
       "2  0x80c2c778e3b73d33:0xbdc58662a4a97d49        <NA>  34.058092 -118.292130   \n",
       "3   0x80c2c89923b27a41:0x32041559418d447        <NA>  34.023669 -118.232930   \n",
       "4  0x80c2c632f933b073:0xc31785961fe826a6        <NA>  34.036694 -118.249421   \n",
       "\n",
       "              category  avg_rating  num_of_reviews price  \\\n",
       "0           [Pharmacy]         4.9              16  <NA>   \n",
       "1   [Textile exporter]         4.5               6  <NA>   \n",
       "2  [Korean restaurant]         4.4              18  <NA>   \n",
       "3       [Fabric store]         3.3               6  <NA>   \n",
       "4       [Fabric store]         4.3               7  <NA>   \n",
       "\n",
       "                                               hours  \\\n",
       "0  [[Friday, 8AM–6PM], [Saturday, 8AM–12PM], [Sun...   \n",
       "1                                               None   \n",
       "2  [[Thursday, 6:30AM–6PM], [Friday, 6:30AM–6PM],...   \n",
       "3  [[Thursday, 9AM–5PM], [Friday, 9AM–5PM], [Satu...   \n",
       "4  [[Thursday, 9AM–5PM], [Friday, 9AM–5PM], [Satu...   \n",
       "\n",
       "                                                MISC              state  \\\n",
       "0  {'Accessibility': ['Wheelchair accessible entr...  Open ⋅ Closes 6PM   \n",
       "1                                               None           Open now   \n",
       "2  {'Accessibility': ['Wheelchair accessible entr...  Open ⋅ Closes 6PM   \n",
       "3  {'Accessibility': None, 'Activities': None, 'A...  Open ⋅ Closes 5PM   \n",
       "4  {'Accessibility': None, 'Activities': None, 'A...  Open ⋅ Closes 5PM   \n",
       "\n",
       "                                    relative_results  \\\n",
       "0  [0x88f16e41929435cf:0x5b2532a2885e9ef6, 0x88f1...   \n",
       "1  [0x80c2c624136ea88b:0xb0315367ed448771, 0x80c2...   \n",
       "2  [0x80c2c78249aba68f:0x35bf16ce61be751d, 0x80c2...   \n",
       "3  [0x80c2c8811477253f:0x23a8a492df1918f7, 0x80c2...   \n",
       "4  [0x80c2c62c496083d1:0xdefa11317fe870a1, 0x80c2...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "1  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "2  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "3  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "4  https://www.google.com/maps/place//data=!4m2!3...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las columnas que nos seran utiles\n",
    "df_2 = df[['name','gmap_id','latitude','longitude','category','avg_rating','num_of_reviews','address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo transformamos a un Data frame de Pandas\n",
    "df_3 = pd.DataFrame(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos las columnas\n",
    "df_3.rename(columns={0:'name', 1:'gmap_id', 2:'latitude', 3:'longitude', 4:'category', 5:'avg_rating', 6:'num_of_reviews', 7:'address'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir la cadena en una lista\n",
    "def str_to_list(s):\n",
    "    if pd.isna(s):\n",
    "        return []  # Manejar valores nulos devolviendo una lista vacía\n",
    "    # Reemplaza los saltos de línea y espacios después de comillas simples con comas\n",
    "    s = s.replace('\\n', '').replace(\"' '\", \"','\")\n",
    "\n",
    "    # Convierte la cadena a una lista de Python\n",
    "    return ast.literal_eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la funcion a la columna 'category'\n",
    "df_3['category'] = df_3['category'].apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos todas las categorias por restaurante\n",
    "df_4 = df_3.explode('category').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Porter Pharmacy</td>\n",
       "      <td>0x88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>32.3883</td>\n",
       "      <td>-83.3571</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>4.9</td>\n",
       "      <td>16</td>\n",
       "      <td>Porter Pharmacy, 129 N Second St, Cochran, GA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Textile</td>\n",
       "      <td>0x80c2c98c0e3c16fd:0x29ec8a728764fdf9</td>\n",
       "      <td>34.018891</td>\n",
       "      <td>-118.21529</td>\n",
       "      <td>Textile exporter</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6</td>\n",
       "      <td>City Textile, 3001 E Pico Blvd, Los Angeles, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Soo Dang</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "      <td>34.058092</td>\n",
       "      <td>-118.29213</td>\n",
       "      <td>Korean restaurant</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "      <td>San Soo Dang, 761 S Vermont Ave, Los Angeles, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nova Fabrics</td>\n",
       "      <td>0x80c2c89923b27a41:0x32041559418d447</td>\n",
       "      <td>34.023669</td>\n",
       "      <td>-118.23293</td>\n",
       "      <td>Fabric store</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6</td>\n",
       "      <td>Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nobel Textile Co</td>\n",
       "      <td>0x80c2c632f933b073:0xc31785961fe826a6</td>\n",
       "      <td>34.036694</td>\n",
       "      <td>-118.249421</td>\n",
       "      <td>Fabric store</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7</td>\n",
       "      <td>Nobel Textile Co, 719 E 9th St, Los Angeles, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202452</th>\n",
       "      <td>Profiles Hair Design</td>\n",
       "      <td>0x8758dd1e2533c991:0x5f6d112918f07dba</td>\n",
       "      <td>43.029664</td>\n",
       "      <td>-108.380849</td>\n",
       "      <td>Beauty salon</td>\n",
       "      <td>4.7</td>\n",
       "      <td>76</td>\n",
       "      <td>Profiles Hair Design, 522 N Federal Blvd, Rive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202453</th>\n",
       "      <td>Profiles Hair Design</td>\n",
       "      <td>0x8758dd1e2533c991:0x5f6d112918f07dba</td>\n",
       "      <td>43.029664</td>\n",
       "      <td>-108.380849</td>\n",
       "      <td>Hair salon</td>\n",
       "      <td>4.7</td>\n",
       "      <td>76</td>\n",
       "      <td>Profiles Hair Design, 522 N Federal Blvd, Rive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202454</th>\n",
       "      <td>Arizona LINE-X</td>\n",
       "      <td>0x872b6f6f24aea445:0x22df9e5dd01e67ba</td>\n",
       "      <td>33.680066</td>\n",
       "      <td>-112.113367</td>\n",
       "      <td>Truck accessories store</td>\n",
       "      <td>4.6</td>\n",
       "      <td>24</td>\n",
       "      <td>Arizona LINE-X, 21242 N Black Canyon Hwy #A, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202455</th>\n",
       "      <td>Arizona LINE-X</td>\n",
       "      <td>0x872b6f6f24aea445:0x22df9e5dd01e67ba</td>\n",
       "      <td>33.680066</td>\n",
       "      <td>-112.113367</td>\n",
       "      <td>Powder coating service</td>\n",
       "      <td>4.6</td>\n",
       "      <td>24</td>\n",
       "      <td>Arizona LINE-X, 21242 N Black Canyon Hwy #A, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202456</th>\n",
       "      <td>US Forest Services Ranger Station</td>\n",
       "      <td>0x875901f1fbd58357:0xed5174d5b088430c</td>\n",
       "      <td>42.829621</td>\n",
       "      <td>-108.72372</td>\n",
       "      <td>Campground</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24</td>\n",
       "      <td>US Forest Services Ranger Station, 333 E Main ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6202457 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  \\\n",
       "0                          Porter Pharmacy   \n",
       "1                             City Textile   \n",
       "2                             San Soo Dang   \n",
       "3                             Nova Fabrics   \n",
       "4                         Nobel Textile Co   \n",
       "...                                    ...   \n",
       "6202452               Profiles Hair Design   \n",
       "6202453               Profiles Hair Design   \n",
       "6202454                     Arizona LINE-X   \n",
       "6202455                     Arizona LINE-X   \n",
       "6202456  US Forest Services Ranger Station   \n",
       "\n",
       "                                       gmap_id   latitude   longitude  \\\n",
       "0        0x88f16e41928ff687:0x883dad4fd048e8f8    32.3883    -83.3571   \n",
       "1        0x80c2c98c0e3c16fd:0x29ec8a728764fdf9  34.018891  -118.21529   \n",
       "2        0x80c2c778e3b73d33:0xbdc58662a4a97d49  34.058092  -118.29213   \n",
       "3         0x80c2c89923b27a41:0x32041559418d447  34.023669  -118.23293   \n",
       "4        0x80c2c632f933b073:0xc31785961fe826a6  34.036694 -118.249421   \n",
       "...                                        ...        ...         ...   \n",
       "6202452  0x8758dd1e2533c991:0x5f6d112918f07dba  43.029664 -108.380849   \n",
       "6202453  0x8758dd1e2533c991:0x5f6d112918f07dba  43.029664 -108.380849   \n",
       "6202454  0x872b6f6f24aea445:0x22df9e5dd01e67ba  33.680066 -112.113367   \n",
       "6202455  0x872b6f6f24aea445:0x22df9e5dd01e67ba  33.680066 -112.113367   \n",
       "6202456  0x875901f1fbd58357:0xed5174d5b088430c  42.829621  -108.72372   \n",
       "\n",
       "                        category avg_rating num_of_reviews  \\\n",
       "0                       Pharmacy        4.9             16   \n",
       "1               Textile exporter        4.5              6   \n",
       "2              Korean restaurant        4.4             18   \n",
       "3                   Fabric store        3.3              6   \n",
       "4                   Fabric store        4.3              7   \n",
       "...                          ...        ...            ...   \n",
       "6202452             Beauty salon        4.7             76   \n",
       "6202453               Hair salon        4.7             76   \n",
       "6202454  Truck accessories store        4.6             24   \n",
       "6202455   Powder coating service        4.6             24   \n",
       "6202456               Campground        4.2             24   \n",
       "\n",
       "                                                   address  \n",
       "0        Porter Pharmacy, 129 N Second St, Cochran, GA ...  \n",
       "1        City Textile, 3001 E Pico Blvd, Los Angeles, C...  \n",
       "2        San Soo Dang, 761 S Vermont Ave, Los Angeles, ...  \n",
       "3        Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...  \n",
       "4        Nobel Textile Co, 719 E 9th St, Los Angeles, C...  \n",
       "...                                                    ...  \n",
       "6202452  Profiles Hair Design, 522 N Federal Blvd, Rive...  \n",
       "6202453  Profiles Hair Design, 522 N Federal Blvd, Rive...  \n",
       "6202454  Arizona LINE-X, 21242 N Black Canyon Hwy #A, P...  \n",
       "6202455  Arizona LINE-X, 21242 N Black Canyon Hwy #A, P...  \n",
       "6202456  US Forest Services Ranger Station, 333 E Main ...  \n",
       "\n",
       "[6202457 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos que este de forma correcta\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Soo Dang</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "      <td>34.058092</td>\n",
       "      <td>-118.29213</td>\n",
       "      <td>Korean restaurant</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "      <td>San Soo Dang, 761 S Vermont Ave, Los Angeles, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vons Chicken</td>\n",
       "      <td>0x80dd2b4c8555edb7:0xfc33d65c4bdbef42</td>\n",
       "      <td>33.916402</td>\n",
       "      <td>-118.010855</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18</td>\n",
       "      <td>Vons Chicken, 12740 La Mirada Blvd, La Mirada,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sweet Rewards Gluten Free Bakery, LLC</td>\n",
       "      <td>0x87ec235c54d25b31:0x3b75fb5facc602f</td>\n",
       "      <td>41.616079</td>\n",
       "      <td>-93.865487</td>\n",
       "      <td>Health food restaurant</td>\n",
       "      <td>4.7</td>\n",
       "      <td>21</td>\n",
       "      <td>Sweet Rewards Gluten Free Bakery, LLC, 85 NE D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Vivi Bubble Tea</td>\n",
       "      <td>0x89c6c89efcaed69d:0xded973f6033e7dba</td>\n",
       "      <td>39.940293</td>\n",
       "      <td>-75.150923</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Vivi Bubble Tea, 701 S 5th St, Philadelphia, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Hale Pops</td>\n",
       "      <td>0x7c00456eecad3111:0x8217f9600c51f33</td>\n",
       "      <td>21.637796</td>\n",
       "      <td>-157.920714</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "      <td>Hale Pops, 55-370 Kamehameha Hwy, Laie, HI 96762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202443</th>\n",
       "      <td>Rosa’s Mexican Grill Chandler</td>\n",
       "      <td>0x872ba99db0ab78db:0x55c826ed8748149d</td>\n",
       "      <td>33.351057</td>\n",
       "      <td>-111.842995</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>4.4</td>\n",
       "      <td>88</td>\n",
       "      <td>Rosa’s Mexican Grill Chandler, 3002 N Arizona ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202445</th>\n",
       "      <td>Domino's Pizza</td>\n",
       "      <td>0x8758dd6a49d17909:0xbe7ccb53ee53e5a7</td>\n",
       "      <td>43.031526</td>\n",
       "      <td>-108.381641</td>\n",
       "      <td>Delivery Restaurant</td>\n",
       "      <td>4.1</td>\n",
       "      <td>178</td>\n",
       "      <td>Domino's Pizza, 804 N Federal Blvd, Riverton, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202446</th>\n",
       "      <td>Domino's Pizza</td>\n",
       "      <td>0x8758dd6a49d17909:0xbe7ccb53ee53e5a7</td>\n",
       "      <td>43.031526</td>\n",
       "      <td>-108.381641</td>\n",
       "      <td>Takeout Restaurant</td>\n",
       "      <td>4.1</td>\n",
       "      <td>178</td>\n",
       "      <td>Domino's Pizza, 804 N Federal Blvd, Riverton, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202447</th>\n",
       "      <td>Domino's Pizza</td>\n",
       "      <td>0x8758dd6a49d17909:0xbe7ccb53ee53e5a7</td>\n",
       "      <td>43.031526</td>\n",
       "      <td>-108.381641</td>\n",
       "      <td>Pizza restaurant</td>\n",
       "      <td>4.1</td>\n",
       "      <td>178</td>\n",
       "      <td>Domino's Pizza, 804 N Federal Blvd, Riverton, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202449</th>\n",
       "      <td>The Green Room Of Libertyville</td>\n",
       "      <td>0x880f96c84b0ef57b:0xe75b67b15a2cfdad</td>\n",
       "      <td>42.28945</td>\n",
       "      <td>-87.954386</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>4.6</td>\n",
       "      <td>228</td>\n",
       "      <td>The Green Room Of Libertyville, 624 Milwaukee ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374126 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  \\\n",
       "2                                 San Soo Dang   \n",
       "6                                 Vons Chicken   \n",
       "10       Sweet Rewards Gluten Free Bakery, LLC   \n",
       "143                            Vivi Bubble Tea   \n",
       "202                                  Hale Pops   \n",
       "...                                        ...   \n",
       "6202443          Rosa’s Mexican Grill Chandler   \n",
       "6202445                         Domino's Pizza   \n",
       "6202446                         Domino's Pizza   \n",
       "6202447                         Domino's Pizza   \n",
       "6202449         The Green Room Of Libertyville   \n",
       "\n",
       "                                       gmap_id   latitude   longitude  \\\n",
       "2        0x80c2c778e3b73d33:0xbdc58662a4a97d49  34.058092  -118.29213   \n",
       "6        0x80dd2b4c8555edb7:0xfc33d65c4bdbef42  33.916402 -118.010855   \n",
       "10        0x87ec235c54d25b31:0x3b75fb5facc602f  41.616079  -93.865487   \n",
       "143      0x89c6c89efcaed69d:0xded973f6033e7dba  39.940293  -75.150923   \n",
       "202       0x7c00456eecad3111:0x8217f9600c51f33  21.637796 -157.920714   \n",
       "...                                        ...        ...         ...   \n",
       "6202443  0x872ba99db0ab78db:0x55c826ed8748149d  33.351057 -111.842995   \n",
       "6202445  0x8758dd6a49d17909:0xbe7ccb53ee53e5a7  43.031526 -108.381641   \n",
       "6202446  0x8758dd6a49d17909:0xbe7ccb53ee53e5a7  43.031526 -108.381641   \n",
       "6202447  0x8758dd6a49d17909:0xbe7ccb53ee53e5a7  43.031526 -108.381641   \n",
       "6202449  0x880f96c84b0ef57b:0xe75b67b15a2cfdad   42.28945  -87.954386   \n",
       "\n",
       "                       category avg_rating num_of_reviews  \\\n",
       "2             Korean restaurant        4.4             18   \n",
       "6                    Restaurant        4.5             18   \n",
       "10       Health food restaurant        4.7             21   \n",
       "143                  Restaurant        4.0              8   \n",
       "202                  Restaurant        4.4             18   \n",
       "...                         ...        ...            ...   \n",
       "6202443      Mexican restaurant        4.4             88   \n",
       "6202445     Delivery Restaurant        4.1            178   \n",
       "6202446      Takeout Restaurant        4.1            178   \n",
       "6202447        Pizza restaurant        4.1            178   \n",
       "6202449              Restaurant        4.6            228   \n",
       "\n",
       "                                                   address  \n",
       "2        San Soo Dang, 761 S Vermont Ave, Los Angeles, ...  \n",
       "6        Vons Chicken, 12740 La Mirada Blvd, La Mirada,...  \n",
       "10       Sweet Rewards Gluten Free Bakery, LLC, 85 NE D...  \n",
       "143      Vivi Bubble Tea, 701 S 5th St, Philadelphia, P...  \n",
       "202       Hale Pops, 55-370 Kamehameha Hwy, Laie, HI 96762  \n",
       "...                                                    ...  \n",
       "6202443  Rosa’s Mexican Grill Chandler, 3002 N Arizona ...  \n",
       "6202445  Domino's Pizza, 804 N Federal Blvd, Riverton, ...  \n",
       "6202446  Domino's Pizza, 804 N Federal Blvd, Riverton, ...  \n",
       "6202447  Domino's Pizza, 804 N Federal Blvd, Riverton, ...  \n",
       "6202449  The Green Room Of Libertyville, 624 Milwaukee ...  \n",
       "\n",
       "[374126 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_filter = df_4['category'].str.contains('restaurant', case=False, na=False) \n",
    "restaurantes = df_4[restaurant_filter]\n",
    "restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Restaurant                                                                     97239\n",
       "Fast food restaurant                                                           28798\n",
       "Takeout Restaurant                                                             23912\n",
       "Pizza restaurant                                                               23812\n",
       "Mexican restaurant                                                             17203\n",
       "                                                                               ...  \n",
       "RestaurantWomen's clothing store                                                   1\n",
       "Event venueChildren's party serviceRestaurant                                      1\n",
       "Farmers' marketTaco restaurant                                                     1\n",
       "Asturian restaurant                                                                1\n",
       "FestivalMen's clothing storeMiddle Eastern restaurantWomen's clothing store        1\n",
       "Name: count, Length: 354, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurantes['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Fast food restaurant    3.821043\n",
       "Name: avg_rating, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comida_rapida = restaurantes[restaurantes['category'] == 'Fast food restaurant']\n",
    "comida_rapida.groupby('category')['avg_rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Takeout Restaurant    3.890775\n",
       "Name: avg_rating, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comida_para_llevar = restaurantes[restaurantes['category'] == 'Takeout Restaurant']\n",
    "comida_para_llevar.groupby('category')['avg_rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Pizza restaurant    4.030976\n",
       "Name: avg_rating, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pizza = restaurantes[restaurantes['category'] == 'Pizza restaurant']\n",
    "pizza.groupby('category')['n'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Mexican restaurant    4.207475\n",
       "Name: avg_rating, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexican = restaurantes[restaurantes['category'] == 'Mexican restaurant']\n",
    "mexican.groupby('category')['avg_rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos por el rubro que escogimos el cual fue restaurantes\n",
    "df_filtrado = df_4[df_4[\"category\"] == \"Mexican restaurant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\1782011620.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos los valores nulos\n",
    "df_filtrado.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17143 entries, 0 to 17202\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   name            17143 non-null  object\n",
      " 1   gmap_id         17143 non-null  object\n",
      " 2   latitude        17143 non-null  object\n",
      " 3   longitude       17143 non-null  object\n",
      " 4   category        17143 non-null  object\n",
      " 5   avg_rating      17143 non-null  object\n",
      " 6   num_of_reviews  17143 non-null  object\n",
      " 7   address         17143 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verificamos los tipos de datos por columna para ver si hay que cambiar algun tipo de dato\n",
    "df_filtrado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion para extraer la ciudad desde la direccion\n",
    "def extraer_ciudad(direccion):\n",
    "\n",
    "    try:\n",
    "        # Dividir la dirección en partes usando la coma como separador\n",
    "        partes = direccion.split(\", \")\n",
    "\n",
    "        # Asegurarse de que haya al menos tres partes (ciudad, estado_código postal)\n",
    "        if len(partes) >= 3:\n",
    "            ciudad = partes[2]  # Extraer la 3ra parte como ciudad\n",
    "            return ciudad\n",
    "        else:\n",
    "            return None # Devolver None para ciudad y estado si tiene la configuración planteada\n",
    "    except IndexError:\n",
    "        return None  # Devolver None para ciudad y estado si la extracción falla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\2889900678.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"city\"] = df_filtrado['address'].apply(extraer_ciudad)\n"
     ]
    }
   ],
   "source": [
    "# Agregamos una columna para colocar la ciudad\n",
    "df_filtrado[\"city\"] = df_filtrado['address'].apply(extraer_ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\567693580.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.drop(columns='address', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos la columna de direccion, ya que la ubicacion exacta la obtenemos con la latitud y longitud\n",
    "df_filtrado.drop(columns='address', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\833960294.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['latitude'] = df_filtrado['latitude'].astype(float)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\833960294.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['longitude'] = df_filtrado['longitude'].astype(float)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\833960294.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['avg_rating'] = df_filtrado['avg_rating'].astype(float)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_16684\\833960294.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['num_of_reviews'] = df_filtrado['num_of_reviews'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos el tipo de dato de las columnas que lo requieren para su correcto funcionamiento\n",
    "df_filtrado['latitude'] = df_filtrado['latitude'].astype(float)\n",
    "df_filtrado['longitude'] = df_filtrado['longitude'].astype(float)\n",
    "df_filtrado['avg_rating'] = df_filtrado['avg_rating'].astype(float)\n",
    "df_filtrado['num_of_reviews'] = df_filtrado['num_of_reviews'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17143 entries, 0 to 17202\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   name            17143 non-null  object \n",
      " 1   gmap_id         17143 non-null  object \n",
      " 2   latitude        17143 non-null  float64\n",
      " 3   longitude       17143 non-null  float64\n",
      " 4   category        17143 non-null  object \n",
      " 5   avg_rating      17143 non-null  float64\n",
      " 6   num_of_reviews  17143 non-null  int32  \n",
      " 7   city            17141 non-null  object \n",
      "dtypes: float64(3), int32(1), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Realizamos una ultima validacion para verificar que los tipos de datos sean correctos y que no hayan valores nulos\n",
    "df_filtrado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el dataset en formato parquet\n",
    "df_filtrado.to_parquet('../Data/Parquet/Sitios.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews por estado\n",
    "A continuacion se realizara la union de los distintos datasets que se nos brindaron para tener en un solo archivo los datos de los reviews y filtrado por la categoria de negocio elegida ('Restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos como variables los directorios de los archivos que vamos a leer y a donde los queremos guardar\n",
    "ruta_entrada = '../Data/Data_limpia/Google/Reviews'\n",
    "ruta_salida = '../Data/Data_transformada/Estados'\n",
    "\n",
    "# Iteramos el directorio para poder abrir cada carpeta de cada estado\n",
    "\n",
    "for carpeta in os.listdir(ruta_entrada):\n",
    "    # guardamos la ruta de la carpeta\n",
    "    path_carpeta = os.path.join(ruta_entrada,carpeta)\n",
    "\n",
    "    # Verificamos que sea una carpeta\n",
    "    if os.path.isdir(path_carpeta):\n",
    "\n",
    "        # Creamos una lista vacia que va a almacenar todos los data frames \n",
    "        dfs = []\n",
    "\n",
    "        # Iteramos la carpeta para leer los archivos\n",
    "        for item in os.listdir(path_carpeta):\n",
    "            # Verificamos que sea un archivo JSON y guardamos su ruta\n",
    "            if item.endswith('.json'):\n",
    "                path_item = os.path.join(path_carpeta,item)\n",
    "\n",
    "                # Leemos el archivo JSON\n",
    "                df = pd.read_json(path_item, lines = True)\n",
    "\n",
    "                # Añadimos el DF a la lista de DFS\n",
    "                dfs.append(df)\n",
    "\n",
    "        # Concatenamos los dataframes para tener un archivo unico      \n",
    "        df_combinado = pd.concat(dfs) \n",
    "\n",
    "        # Definimos la ruta de salida\n",
    "        salida = os.path.join(ruta_salida, f'{carpeta}.parquet')\n",
    "\n",
    "        # Guardamos el data frame en formato parquet\n",
    "        df_combinado.to_parquet(salida, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.140438e+20</td>\n",
       "      <td>Kanisha Mixon</td>\n",
       "      <td>1597168272670</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Personable staff! Beautiful and clean env...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.160090e+20</td>\n",
       "      <td>Brandie Hodges</td>\n",
       "      <td>1609899039594</td>\n",
       "      <td>5</td>\n",
       "      <td>Best clothing intown</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062399e+20</td>\n",
       "      <td>Sharon King</td>\n",
       "      <td>1547235290843</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.049701e+20</td>\n",
       "      <td>Veronica Pierce</td>\n",
       "      <td>1517709403534</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.105875e+20</td>\n",
       "      <td>Whitney Waldon Collier</td>\n",
       "      <td>1535245718492</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                    name           time  rating  \\\n",
       "0  1.140438e+20           Kanisha Mixon  1597168272670       5   \n",
       "1  1.160090e+20          Brandie Hodges  1609899039594       5   \n",
       "2  1.062399e+20             Sharon King  1547235290843       4   \n",
       "3  1.049701e+20         Veronica Pierce  1517709403534       5   \n",
       "4  1.105875e+20  Whitney Waldon Collier  1535245718492       5   \n",
       "\n",
       "                                                text  pics  resp  \\\n",
       "0  Very Personable staff! Beautiful and clean env...  None  None   \n",
       "1                               Best clothing intown  None  None   \n",
       "2                                               None  None  None   \n",
       "3                                               None  None  None   \n",
       "4                                               None  None  None   \n",
       "\n",
       "                                 gmap_id  \n",
       "0  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  \n",
       "1  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  \n",
       "2  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  \n",
       "3  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  \n",
       "4  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos uno de los datasets extraidos para verificar que este de la forma correcta\n",
    "df = pd.read_parquet('../Data/Data_transformada/Estados/review-Alabama.parquet')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_entrada = '../Data/Data_transformada/Estados'\n",
    "ruta_salida = '../Data/Data_transformada/Filtrados'\n",
    "\n",
    "# Ruta que contiene los sitios\n",
    "sitios_metadata = \"../Data/Parquet/Sitios.parquet\"\n",
    "\n",
    "df_sitios = pd.read_parquet(sitios_metadata)\n",
    "\n",
    "# Iteramos el directorio donde se encuentran los archivos antes extraidos\n",
    "for item in os.listdir(ruta_entrada):\n",
    "\n",
    "    # Cverificamos que sea un archivo parquet\n",
    "    if item.endswith(\".parquet\"):\n",
    "        # Leemos el archivo con Pandas\n",
    "        df = pd.read_parquet(os.path.join(ruta_entrada, item))\n",
    "        \n",
    "        # Funcion para transformar en 'yes' si tiene datos la celda o en 'no' si esta vacia \n",
    "        def replace_none(value):\n",
    "            if value is None:\n",
    "                return \"No\"\n",
    "            else:\n",
    "                return \"Yes\"\n",
    "            \n",
    "        # Aplicamos la funcion en la columna 'resp' para saber si tiene respuesta el review o no\n",
    "        df[\"resp\"] = df[\"resp\"].apply(replace_none)\n",
    "        \n",
    "        # Eliminamos la columna 'pics' ya que no nos proporciona informacion valiosa\n",
    "        df.drop([\"pics\"], axis=1, inplace=True)\n",
    "        \n",
    "        # Eliminamos los duplicados\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "        # Renombramos la columna 'name' la cual contiene el nombre del usuario\n",
    "        df.rename(columns={\"name\": \"user_name\"}, inplace = True)\n",
    "\n",
    "        # Aplicamos un Merge con el dataset de los sitios para hacer el filtro de los restaurantes\n",
    "        df = df.merge(\n",
    "            df_sitios[[\"gmap_id\", \"name\", \"category\", \"city\"]],\n",
    "            on=\"gmap_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # Renombramos la columna 'name' la cual pertenece al nombre de la tienda\n",
    "        df.rename(columns={\"name\": 'business_name'}, inplace = True)\n",
    "\n",
    "        # Eliminamos valores nulos en las columnas importantes\n",
    "        df = df.dropna(subset=[\"business_name\", \"city\"])\n",
    "\n",
    "        # Estraemos el estado del nombre del archivo parquet\n",
    "        state_name = item.split(\"-\")[-1].split(\".\")[0]\n",
    "\n",
    "        # Agregamos una columna que especifica el nombre del estado en el que se realizo el review\n",
    "        df[\"State_review\"] = state_name\n",
    "\n",
    "        # Configuramos el directorio de salida para cada archivo y se exporta en tipo parquet\n",
    "        output_file_path = os.path.join(ruta_salida, item)\n",
    "        df.to_parquet(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de tener los archivos listos por estado, hacemos un pequeño analisis para ver que estado tendremos en cuenta segun la cantidad de reviews de restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de los archivos ya filtrados\n",
    "ruta_entrada = '../Data/Data_transformada/Filtrados'\n",
    "\n",
    "# Creamos una lista vacia para almacenar los dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iteramos la carpeta\n",
    "for item in os.listdir(ruta_entrada):\n",
    "    # Verificamos que sea un archivo parquet\n",
    "    if item.endswith(\".parquet\"):\n",
    "        # RLeemos el parquet por medio de Pandas\n",
    "        df = pd.read_parquet(os.path.join(ruta_entrada, item))\n",
    "\n",
    "        # Agregamos el Dataframe a la lista\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenamos todos los datos en un solo dataframe para poder compararlos\n",
    "df_Google_reviews_CS = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100976, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos la cantidad de registros\n",
    "df_Google_reviews_CS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State_review\n",
       "California              123218\n",
       "Texas                    96517\n",
       "Florida                  67325\n",
       "Illinois                 61815\n",
       "Arizona                  51188\n",
       "Georgia                  46830\n",
       "New_York                 41755\n",
       "Colorado                 37502\n",
       "Michigan                 35934\n",
       "Ohio                     33053\n",
       "North_Carolina           30444\n",
       "Oregon                   29485\n",
       "Indiana                  28245\n",
       "Washington               28031\n",
       "Virginia                 25057\n",
       "Utah                     24518\n",
       "Tennessee                23242\n",
       "Nevada                   22045\n",
       "Missouri                 21524\n",
       "Wisconsin                20822\n",
       "Oklahoma                 19363\n",
       "New_Jersey               19348\n",
       "New_Mexico               17214\n",
       "South_Carolina           17141\n",
       "Louisiana                16363\n",
       "Pennsylvania             15934\n",
       "Arkansas                 15106\n",
       "Kansas                   14205\n",
       "Kentucky                 13599\n",
       "Iowa                     12918\n",
       "Minnesota                12345\n",
       "Maryland                 11558\n",
       "Alabama                  10046\n",
       "Massachusetts             9445\n",
       "Nebraska                  7178\n",
       "Connecticut               6544\n",
       "Idaho                     5824\n",
       "Mississippi               5034\n",
       "West_Virginia             3329\n",
       "Hawaii                    3119\n",
       "Delaware                  2471\n",
       "Rhode_Island              2170\n",
       "Wyoming                   2081\n",
       "Montana                   2067\n",
       "New_Hampshire             1496\n",
       "Maine                     1457\n",
       "Alaska                    1384\n",
       "South_Dakota              1276\n",
       "North_Dakota              1183\n",
       "Vermont                    676\n",
       "District_of_Columbia       552\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos la cantidad de registros por estado\n",
    "df_Google_reviews_CS['State_review'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de este pequeño analisis decidimos escoger el estado de Florida como enfoque, por lo tanto, realizaremos los ultimos detalles para por ultimo, exportar el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_name\n",
       "Taco Bell                                  1\n",
       "Crema Restaurante                          1\n",
       "Sabor Latino                               1\n",
       "Lucky Luna                                 1\n",
       "Puebla Corner Deli                         1\n",
       "                                          ..\n",
       "El Toro Mexican Restaurant                 1\n",
       "Picante American & Mexican Grill           1\n",
       "Raymond's Taco's no.3                      1\n",
       "Taco's El Norte                            1\n",
       "Fiesta Guadalajara | Mexican Restaurant    1\n",
       "Name: count, Length: 8150, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Google_reviews_CS['business_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = df_Google_reviews_CS['business_name'].unique()\n",
    "prueba1 = df_Google_reviews_CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba1.drop_duplicates(subset='business_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State_review\n",
       "California              1118\n",
       "Texas                    862\n",
       "Illinois                 545\n",
       "New_York                 517\n",
       "Arizona                  274\n",
       "Georgia                  262\n",
       "Washington               249\n",
       "New_Jersey               243\n",
       "Colorado                 241\n",
       "North_Carolina           218\n",
       "Oregon                   215\n",
       "Florida                  211\n",
       "Indiana                  172\n",
       "Tennessee                167\n",
       "Oklahoma                 154\n",
       "Ohio                     143\n",
       "Virginia                 141\n",
       "Arkansas                 139\n",
       "Pennsylvania             136\n",
       "Nevada                   131\n",
       "New_Mexico               128\n",
       "Missouri                 127\n",
       "Michigan                 126\n",
       "Kentucky                 121\n",
       "Kansas                   115\n",
       "Wisconsin                115\n",
       "Alabama                  109\n",
       "Utah                     106\n",
       "Louisiana                106\n",
       "Iowa                     105\n",
       "Maryland                 104\n",
       "South_Carolina           102\n",
       "Massachusetts            102\n",
       "Minnesota                 88\n",
       "Connecticut               82\n",
       "Mississippi               57\n",
       "Nebraska                  56\n",
       "Idaho                     55\n",
       "Delaware                  31\n",
       "Hawaii                    31\n",
       "Wyoming                   17\n",
       "Alaska                    17\n",
       "Rhode_Island              16\n",
       "District_of_Columbia      15\n",
       "West_Virginia             15\n",
       "Montana                   14\n",
       "Maine                     14\n",
       "New_Hampshire             12\n",
       "North_Dakota              10\n",
       "South_Dakota               9\n",
       "Vermont                    7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba1['State_review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo correspondiente al estado de Florida\n",
    "florida_df = pd.read_parquet('../Data/Data_transformada/Filtrados/review-Florida.parquet')\n",
    "califronia_df = pd.read_parquet('../Data/Data_transformada/Filtrados/review-California.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_name\n",
       "El Norteno                                3.071429\n",
       "K' Rico's Restaurant                      3.200000\n",
       "Down N' Dirty Tacos                       3.333333\n",
       "Taco 71                                   3.363636\n",
       "Mexico Bravo Now MEX Mexican Grill        3.384615\n",
       "                                            ...   \n",
       "Rincon Tolteca Mexican restaurant corp    4.954545\n",
       "Taqueria El Molcajete                     5.000000\n",
       "EL CAMION DEL TACO                        5.000000\n",
       "Red Roc Cravings                          5.000000\n",
       "TacoSchool El Compadre                    5.000000\n",
       "Name: rating, Length: 229, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "florida_df.groupby('business_name')['rating'].mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67325 entries, 0 to 67324\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   user_id        67325 non-null  float64\n",
      " 1   user_name      67325 non-null  object \n",
      " 2   time           67325 non-null  int64  \n",
      " 3   rating         67325 non-null  int64  \n",
      " 4   text           39360 non-null  object \n",
      " 5   resp           67325 non-null  object \n",
      " 6   gmap_id        67325 non-null  object \n",
      " 7   business_name  67325 non-null  object \n",
      " 8   category       67325 non-null  object \n",
      " 9   city           67325 non-null  object \n",
      " 10  State_review   67325 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 5.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123218 entries, 0 to 123217\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   user_id        123218 non-null  float64\n",
      " 1   user_name      123218 non-null  object \n",
      " 2   time           123218 non-null  int64  \n",
      " 3   rating         123218 non-null  int64  \n",
      " 4   text           70093 non-null   object \n",
      " 5   resp           123218 non-null  object \n",
      " 6   gmap_id        123218 non-null  object \n",
      " 7   business_name  123218 non-null  object \n",
      " 8   category       123218 non-null  object \n",
      " 9   city           123218 non-null  object \n",
      " 10  State_review   123218 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los tipos de datos y los valores nulos\n",
    "florida_df.info()\n",
    "califronia_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion que permite extraer la fecha y la hora desde la columna de time\n",
    "\n",
    "def convert_timestamp_ms_to_datetime(timestamp_ms):\n",
    "    \"\"\"\n",
    "    Convierte un timestamp en milisegundos a un objeto datetime.\n",
    "    \"\"\"\n",
    "    if pd.isna(timestamp_ms):\n",
    "        return None\n",
    "    # Convertir a segundos\n",
    "    timestamp_s = timestamp_ms / 1000.0\n",
    "    # Convertir a datetime\n",
    "    return datetime.fromtimestamp(timestamp_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la funcion a la columna de time\n",
    "florida_df['time'] = florida_df['time'].apply(convert_timestamp_ms_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las columnas de fecha, hora y dia de la semana a partir de la fecha extraida anteriormente\n",
    "florida_df['date'] = florida_df['time'].dt.normalize()\n",
    "florida_df['hour'] = florida_df['time'].dt.hour\n",
    "florida_df['day'] = florida_df['time'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>State_review</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176490e+20</td>\n",
       "      <td>Jane Cook</td>\n",
       "      <td>2015-05-25 17:56:04.403</td>\n",
       "      <td>5</td>\n",
       "      <td>any time we are in Pompano Beach we go for lun...</td>\n",
       "      <td>No</td>\n",
       "      <td>0x88d90319155c44a9:0x9abfade11830d0ca</td>\n",
       "      <td>Starlight Restaurant &amp; Lounge</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2015-05-25</td>\n",
       "      <td>17</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.041909e+20</td>\n",
       "      <td>Mark Felix</td>\n",
       "      <td>2017-11-14 09:40:32.156</td>\n",
       "      <td>4</td>\n",
       "      <td>Good service. Food was so so.</td>\n",
       "      <td>No</td>\n",
       "      <td>0x88d90319155c44a9:0x9abfade11830d0ca</td>\n",
       "      <td>Starlight Restaurant &amp; Lounge</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>9</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.121549e+20</td>\n",
       "      <td>Yanio w Alfonso</td>\n",
       "      <td>2018-08-19 06:48:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>Nasty place and very expensive.</td>\n",
       "      <td>No</td>\n",
       "      <td>0x88d90319155c44a9:0x9abfade11830d0ca</td>\n",
       "      <td>Starlight Restaurant &amp; Lounge</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>6</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.126933e+20</td>\n",
       "      <td>Carlos San Luis</td>\n",
       "      <td>2018-01-01 15:27:14.949</td>\n",
       "      <td>5</td>\n",
       "      <td>Good mexican food</td>\n",
       "      <td>No</td>\n",
       "      <td>0x88d90319155c44a9:0x9abfade11830d0ca</td>\n",
       "      <td>Starlight Restaurant &amp; Lounge</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.131080e+20</td>\n",
       "      <td>Maigra Hernandez</td>\n",
       "      <td>2018-03-04 15:17:22.630</td>\n",
       "      <td>5</td>\n",
       "      <td>Tacos were great</td>\n",
       "      <td>No</td>\n",
       "      <td>0x88d90319155c44a9:0x9abfade11830d0ca</td>\n",
       "      <td>Starlight Restaurant &amp; Lounge</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>15</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         user_name                    time  rating  \\\n",
       "0  1.176490e+20         Jane Cook 2015-05-25 17:56:04.403       5   \n",
       "1  1.041909e+20        Mark Felix 2017-11-14 09:40:32.156       4   \n",
       "2  1.121549e+20   Yanio w Alfonso 2018-08-19 06:48:00.000       1   \n",
       "3  1.126933e+20   Carlos San Luis 2018-01-01 15:27:14.949       5   \n",
       "4  1.131080e+20  Maigra Hernandez 2018-03-04 15:17:22.630       5   \n",
       "\n",
       "                                                text resp  \\\n",
       "0  any time we are in Pompano Beach we go for lun...   No   \n",
       "1                      Good service. Food was so so.   No   \n",
       "2                    Nasty place and very expensive.   No   \n",
       "3                                  Good mexican food   No   \n",
       "4                                   Tacos were great   No   \n",
       "\n",
       "                                 gmap_id                  business_name  \\\n",
       "0  0x88d90319155c44a9:0x9abfade11830d0ca  Starlight Restaurant & Lounge   \n",
       "1  0x88d90319155c44a9:0x9abfade11830d0ca  Starlight Restaurant & Lounge   \n",
       "2  0x88d90319155c44a9:0x9abfade11830d0ca  Starlight Restaurant & Lounge   \n",
       "3  0x88d90319155c44a9:0x9abfade11830d0ca  Starlight Restaurant & Lounge   \n",
       "4  0x88d90319155c44a9:0x9abfade11830d0ca  Starlight Restaurant & Lounge   \n",
       "\n",
       "             category           city State_review       date  hour      day  \n",
       "0  Mexican restaurant  Pompano Beach      Florida 2015-05-25    17   Monday  \n",
       "1  Mexican restaurant  Pompano Beach      Florida 2017-11-14     9  Tuesday  \n",
       "2  Mexican restaurant  Pompano Beach      Florida 2018-08-19     6   Sunday  \n",
       "3  Mexican restaurant  Pompano Beach      Florida 2018-01-01    15   Monday  \n",
       "4  Mexican restaurant  Pompano Beach      Florida 2018-03-04    15   Sunday  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos que este correcto\n",
    "florida_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna time, ya que los datos los extraimos en otras columnas\n",
    "florida_df.drop(columns={'time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los valores nulos ya que el dataset aun es muy grande y necesitamos reducir el volumen de datos\n",
    "florida_df.dropna(inplace=True)\n",
    "florida_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67325 entries, 0 to 67324\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   user_id        67325 non-null  float64       \n",
      " 1   user_name      67325 non-null  object        \n",
      " 2   rating         67325 non-null  int64         \n",
      " 3   text           39360 non-null  object        \n",
      " 4   resp           67325 non-null  object        \n",
      " 5   gmap_id        67325 non-null  object        \n",
      " 6   business_name  67325 non-null  object        \n",
      " 7   category       67325 non-null  object        \n",
      " 8   city           67325 non-null  object        \n",
      " 9   State_review   67325 non-null  object        \n",
      " 10  date           67325 non-null  datetime64[ns]\n",
      " 11  hour           67325 non-null  int32         \n",
      " 12  day            67325 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), int64(1), object(9)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Validar que los tipos de datos esten correctos\n",
    "florida_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL rango de fechas para el analisis va desde el 2009-05-11 00:00:00 hasta el 2021-08-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Vemos el rango de fechas que tenemos para el analisis\n",
    "\n",
    "fecha_minima = florida_df['date'].min()\n",
    "fecha_maxima = florida_df['date'].max()\n",
    "\n",
    "print(f'EL rango de fechas para el analisis va desde el {fecha_minima} hasta el {fecha_maxima}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el dataset en un archivo tipo parquet\n",
    "florida_df.to_parquet('../Data/Parquet/Reviews_florida.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "califronia_df['time'] = califronia_df['time'].apply(convert_timestamp_ms_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las columnas de fecha, hora y dia de la semana a partir de la fecha extraida anteriormente\n",
    "califronia_df['date'] = califronia_df['time'].dt.normalize()\n",
    "califronia_df['hour'] = califronia_df['time'].dt.hour\n",
    "califronia_df['day'] = califronia_df['time'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>State_review</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.089843e+20</td>\n",
       "      <td>Edgar Alexander Lara</td>\n",
       "      <td>2021-04-13 00:03:26.946</td>\n",
       "      <td>4</td>\n",
       "      <td>A delicious variety of food. Good place to go ...</td>\n",
       "      <td>No</td>\n",
       "      <td>0x80c2d765f8c90a3d:0x16afb75943e7ad50</td>\n",
       "      <td>Cowboy Burgers &amp; BBQ</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.089843e+20</td>\n",
       "      <td>Edgar Alexander Lara</td>\n",
       "      <td>2021-04-13 00:03:26.946</td>\n",
       "      <td>4</td>\n",
       "      <td>A delicious variety of food. Good place to go ...</td>\n",
       "      <td>No</td>\n",
       "      <td>0x80c2d765f8c90a3d:0x16afb75943e7ad50</td>\n",
       "      <td>Cowboy Burgers &amp; BBQ</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.022832e+20</td>\n",
       "      <td>Selena Mejia</td>\n",
       "      <td>2014-06-15 21:13:10.840</td>\n",
       "      <td>1</td>\n",
       "      <td>I use to love cowboys ever since I was a teen....</td>\n",
       "      <td>No</td>\n",
       "      <td>0x80c2d765f8c90a3d:0x16afb75943e7ad50</td>\n",
       "      <td>Cowboy Burgers &amp; BBQ</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>2014-06-15</td>\n",
       "      <td>21</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.022832e+20</td>\n",
       "      <td>Selena Mejia</td>\n",
       "      <td>2014-06-15 21:13:10.840</td>\n",
       "      <td>1</td>\n",
       "      <td>I use to love cowboys ever since I was a teen....</td>\n",
       "      <td>No</td>\n",
       "      <td>0x80c2d765f8c90a3d:0x16afb75943e7ad50</td>\n",
       "      <td>Cowboy Burgers &amp; BBQ</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>2014-06-15</td>\n",
       "      <td>21</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.113197e+20</td>\n",
       "      <td>Roderick Conwi</td>\n",
       "      <td>2016-02-21 16:32:39.368</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like going to mom and pop burger joints...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0x80c2d765f8c90a3d:0x16afb75943e7ad50</td>\n",
       "      <td>Cowboy Burgers &amp; BBQ</td>\n",
       "      <td>Mexican restaurant</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id             user_name                    time  rating  \\\n",
       "0  1.089843e+20  Edgar Alexander Lara 2021-04-13 00:03:26.946       4   \n",
       "1  1.089843e+20  Edgar Alexander Lara 2021-04-13 00:03:26.946       4   \n",
       "2  1.022832e+20          Selena Mejia 2014-06-15 21:13:10.840       1   \n",
       "3  1.022832e+20          Selena Mejia 2014-06-15 21:13:10.840       1   \n",
       "4  1.113197e+20        Roderick Conwi 2016-02-21 16:32:39.368       4   \n",
       "\n",
       "                                                text resp  \\\n",
       "0  A delicious variety of food. Good place to go ...   No   \n",
       "1  A delicious variety of food. Good place to go ...   No   \n",
       "2  I use to love cowboys ever since I was a teen....   No   \n",
       "3  I use to love cowboys ever since I was a teen....   No   \n",
       "4  If you like going to mom and pop burger joints...  Yes   \n",
       "\n",
       "                                 gmap_id         business_name  \\\n",
       "0  0x80c2d765f8c90a3d:0x16afb75943e7ad50  Cowboy Burgers & BBQ   \n",
       "1  0x80c2d765f8c90a3d:0x16afb75943e7ad50  Cowboy Burgers & BBQ   \n",
       "2  0x80c2d765f8c90a3d:0x16afb75943e7ad50  Cowboy Burgers & BBQ   \n",
       "3  0x80c2d765f8c90a3d:0x16afb75943e7ad50  Cowboy Burgers & BBQ   \n",
       "4  0x80c2d765f8c90a3d:0x16afb75943e7ad50  Cowboy Burgers & BBQ   \n",
       "\n",
       "             category          city State_review       date  hour      day  \n",
       "0  Mexican restaurant  Baldwin Park   California 2021-04-13     0  Tuesday  \n",
       "1  Mexican restaurant  Baldwin Park   California 2021-04-13     0  Tuesday  \n",
       "2  Mexican restaurant  Baldwin Park   California 2014-06-15    21   Sunday  \n",
       "3  Mexican restaurant  Baldwin Park   California 2014-06-15    21   Sunday  \n",
       "4  Mexican restaurant  Baldwin Park   California 2016-02-21    16   Sunday  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "califronia_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "califronia_df.drop(columns={'time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EL rango de fechas para el analisis va desde el 2003-10-30 00:00:00 hasta el 2021-09-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Vemos el rango de fechas que tenemos para el analisis\n",
    "\n",
    "fecha_minima = califronia_df['date'].min()\n",
    "fecha_maxima = califronia_df['date'].max()\n",
    "\n",
    "print(f'EL rango de fechas para el analisis va desde el {fecha_minima} hasta el {fecha_maxima}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el dataset en un archivo tipo parquet\n",
    "califronia_df.to_parquet('../Data/Parquet/Reviews_california.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
